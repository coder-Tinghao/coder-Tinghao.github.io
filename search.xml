<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>GFS论文总结</title>
    <url>/2023/02/13/GFS%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="GFS论文总结"><a href="#GFS论文总结" class="headerlink" title="GFS论文总结"></a>GFS论文总结</h1><p>GFS（The Google File System），Google的目标是构建一个大型的，快速的文件系统。并且这个文件系统是全局有效的，这样各种不同的应用程序都可以从中读取数据。从硬件到使用了GFS的软件都有讨论，并且它也是一个成功的现实世界的设计。尽管这是在学术会议上发表的学术论文，但是文章里介绍的东西（GFS）也相当成功，并且在现实世界中使用了相当长的时间。</p>
<h1 id="分布式存储系统"><a href="#分布式存储系统" class="headerlink" title="分布式存储系统"></a>分布式存储系统</h1><p>存储是一种关键的抽象，可能有各种各样重要的抽象可以应用在分布式系统中，简单的存储接口往往非常有用且极其通用。所以，构建分布式系统大多都是关于如何设计存储系统，或是设计其它基于大型分布式存储的系统。所以我们会更加关注如何为大型分布式存储系统设计一个优秀的接口，以及如何设计存储系统的内部结构，这样系统才能良好运行。<br><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/distributed_system.png?raw=true" alt="分布式系统"></p>
<p>1.对于分布式存储，为了获取更大的性能，利用数百台计算机的资源来同时完成大量工作</p>
<p>2.将数据分割放到大量的服务器上，这样就可以并行的从多台服务器读取数据。我们将这种方式称之为分片（Sharding）</p>
<p>3.分片导致常态的错误，需要自动化的方法而不是人工介入来修复错误，引出容错</p>
<p>4.实现容错最有用的一种方法是使用复制，只需要维护2-3个数据的副本，当其中一个故障了，你就可以使用另一个。所以，如果想要容错能力，就得有复制（replication）</p>
<p>5.如果有复制，那就有了两份数据的副本。可以确定的是，如果你不小心，它们就会不一致。获取到的数据内容也将取决于你向哪个副本请求数据。这对于应用程序来说就有些麻烦了。所以，如果我们有了复制，我们就有不一致的问题（inconsistency）</p>
<p>6.避免不一致的问题，并且让数据看起来也表现的符合预期。但是为了达到这样的效果，你总是需要额外的工作，需要不同服务器之间通过网络额外的交互，而这样的交互会降低性能。所以如果你想要一致性，你的代价就是低性能。</p>
<p><strong>通常，人们很少会乐意为好的一致性付出相应的性能代价。</strong></p>
<h1 id="GFS系统设计"><a href="#GFS系统设计" class="headerlink" title="GFS系统设计"></a>GFS系统设计</h1><p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/GFS_architecture.png?raw=true" alt="GFS结构"></p>
<h2 id="GFS设计目标"><a href="#GFS设计目标" class="headerlink" title="GFS设计目标"></a>GFS设计目标</h2><p>为了获得大容量和高速的特性，每个包含了数据的文件会被GFS自动的分割并存放在多个服务器之上，这样读写操作自然就会变得很快。因为可以从多个服务器上同时读取同一个文件，进而获得更高的聚合吞吐量。将文件分割存储还可以在存储系统中保存比单个磁盘还要大的文件。</p>
<p><strong>GFS是为TB级别的文件而生。并且GFS只会顺序处理，不支持随机访问</strong></p>
<h2 id="GFS-Master节点"><a href="#GFS-Master节点" class="headerlink" title="GFS Master节点"></a>GFS Master节点</h2><p>Master节点用来管理文件和Chunk的信息，而Chunk服务器用来存储实际的数据。Master节点知道每一个文件对应的所有的Chunk的ID，这些Chunk每个是64MB大小，它们共同构成了一个文件。如果我有一个1GB的文件，那么Master节点就知道文件的第一个Chunk存储在哪，第二个Chunk存储在哪，等等。当我想读取这个文件中的任意一个部分时，我需要向Master节点查询对应的Chunk在哪个服务器上，之后我可以直接从Chunk服务器读取对应的Chunk数据。</p>
<p>Master节点主要保存了两个表单：</p>
<p>1.文件名到Chunk ID或者Chunk Handle数组的对应。这个表单告诉你，文件对应了哪些Chunk。</p>
<p>2.记录了Chunk ID到Chunk数据的对应关系。这里的数据又包括了：<br><strong>每个Chunk存储在哪些服务器上</strong>；<strong>每个Chunk当前的版本号</strong>；<strong>哪个Chunk服务器持有主Chunk</strong>，所有对于Chunk的写操作都必须在主Chunk（Primary Chunk）上顺序处理，主Chunk是Chunk的多个副本之一；<br><strong>主Chunk的租约过期时间</strong>，主Chunk只能在特定的租约时间内担任主Chunk</p>
<p>Master会在磁盘上存储log，每次有数据变更时，Master会在磁盘的log中追加一条记录，并生成CheckPoint（类似于备份点）</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/GFS_Master.png?raw=true" alt="GFS_Master"></p>
<p>有些数据需要存在磁盘上，而有些不用。它们分别是：<br>如图所示，需要保存在磁盘上的，标记为NV（non-volatile, 非易失）；不需要保存在磁盘上的标记为V</p>
<p>任何时候，如果文件扩展到达了一个新的64MB，需要新增一个Chunk或者由于指定了新的主Chunk而导致版本号更新了，Master节点需要向磁盘中的Log追加一条记录。这里在磁盘中维护log而不是数据库的原因是，数据库本质上来说是某种B树（b-tree）或者hash table，相比之下，<strong>追加log会非常的高效</strong>，因为你可以将最近的<strong>多个log记录一次性的写入磁盘</strong>。因为这些数据都是向同一个地址追加，这样只需要等待磁盘的磁碟旋转一次。而对于B树来说，每一份数据都需要在磁盘中随机找个位置写入。</p>
<p>Master节点重启时，会从log中的最近一个<strong>checkpoint</strong>开始恢复，再逐条执行从Checkpoint开始的log，最后恢复自己的状态。</p>
<h2 id="GFS读文件"><a href="#GFS读文件" class="headerlink" title="GFS读文件"></a>GFS读文件</h2><p>读请求，意味着应用程序或者GFS客户端有一个文件名和它想从文件的某个位置读取的偏移量（offset），应用程序会将这些信息发送给Master节点。Master节点会从自己的file表单中查询文件名，得到Chunk ID的数组。因为每个Chunk是64MB，所以偏移量除以64MB就可以从数组中得到对应的Chunk ID。之后Master再从Chunk表单中找到存有Chunk的服务器列表，并将列表返回给客户端。所以，第一步是客户端（或者应用程序）将文件名和偏移量发送给Master。第二步，Master节点将Chunk Handle（也就是ID，记为H）和服务器列表发送给客户端。</p>
<p>客户端可以从这些Chunk服务器中挑选一个来读取数据。GFS论文说，客户端会选择一个网络上最近的服务器（Google的数据中心中，IP地址是连续的，所以可以从IP地址的差异判断网络位置的远近），并将读请求发送到那个服务器。因为客户端每次可能只读取1MB或者64KB数据，所以，客户端可能会连续多次读取同一个Chunk的不同位置。所以，客户端会缓存Chunk和服务器的对应关系。</p>
<p>客户端会与选出的Chunk服务器通信，将Chunk Handle和偏移量发送给那个Chunk服务器。Chunk服务器会在本地的硬盘上，将每个Chunk存储成独立的Linux文件，并通过普通的Linux文件系统管理</p>
<h2 id="GFS写文件"><a href="#GFS写文件" class="headerlink" title="GFS写文件"></a>GFS写文件</h2><p>写文件，客户端会向Master节点发送请求说：我想向这个文件名对应的文件追加数据，请告诉我文件中<strong>最后一个Chunk的位置</strong>。这就是GFS论文中讨论的<strong>记录追加（Record Append）</strong></p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/GFS_write.png?raw=true" alt="GFS写操作"></p>
<p>GFS 使用了**租约(lease)**的手段，Master 会定期向 chunk 的某个 replica 所在的服务器进行授权（有超时时间，所以称为租约），拿到授权的副本称为主副本（primary replica），由其进行写入顺序的安排。</p>
<p>对于读文件来说，可以从任何最新的Chunk副本读取数据，但是对于写文件来说，必须要通过Chunk的主副本（Primary Chunk）来写入。对于Master节点来说，如果发现Chunk的主副本不存在，Master会找出所有存有Chunk最新副本的Chunk服务器。每个Chunk可能同时有多个副本，最新的副本是指，副本中保存的版本号与Master中记录的Chunk的版本号一致。当客户端想要对文件进行追加，但是又不知道文件尾的Chunk对应的Primary在哪时，Master会等所有存储了最新Chunk版本的服务器集合完成，然后挑选一个作为Primary，其他的作为Secondary。</p>
<p>现在我们有了一个Primary，它可以接收来自客户端的写请求，并将写请求应用在多个Chunk服务器中。这样Master可以将实际更新Chunk的能力转移给Primary服务器。并且在将版本号更新到Primary和Secondary服务器之后，如果Master节点故障重启，还是可以在相同的Primary和Secondary服务器上继续更新Chunk。</p>
<h2 id="GFS一致性"><a href="#GFS一致性" class="headerlink" title="GFS一致性"></a>GFS一致性</h2><p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/GFS_consistency.png?raw=true" alt="GFS一致性"></p>
<p>如图所示，追加A成功，追加B时第三个副本失败，追加C成功，而后重新追加B会在C的后面追加。</p>
<p>在GFS的这种工作方式下，如果Primary返回写入成功，那么一切都还好，如果Primary返回写入失败，就不是那么好了。Primary返回写入失败会导致不同的副本有完全不同的数据。</p>
<h2 id="GFS问题"><a href="#GFS问题" class="headerlink" title="GFS问题"></a>GFS问题</h2><p>它最严重的局限可能在于，它只有一个Master节点，会带来以下问题：</p>
<p>·Master节点必须为每个文件，每个Chunk维护表单，随着GFS的应用越来越多，涉及的文件也越来越多，最终Master会耗尽内存来存储文件表单。你可以增加内存，但是单台计算机的内存也是有上限的。</p>
<p>·单个Master节点要承载数千个客户端的请求，而Master节点的CPU每秒只能处理数百个请求，尤其Master还需要将部分数据写入磁盘，很快，客户端数量超过了单个Master的能力。</p>
<p>·应用程序发现很难处理GFS奇怪的语义（本节最开始介绍的GFS的副本数据的同步，或者可以说不同步）。</p>
<p>·Master节点的故障切换不是自动的。GFS需要人工干预来处理已经永久故障的Master节点，并更换新的服务器，这可能需要几十分钟甚至更长的而时间来处理。对于某些应用程序来说，这个时间太长了。</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Mapreduce论文总结</title>
    <url>/2023/02/05/Mapreduce%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近决定通过MIT6.824的分布式课程学习一下Google的三篇经典论文，Mapreduce、GFS、Raft。6.824课程相关链接如下：</p>
<p><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-01-introduction">6.824课程翻译链接</a></p>
<p><a href="https://www.bilibili.com/video/av87684880/?vd_source=cc4910ad55a90281a3f278b41a379e5b">2020课程视频链接（带字幕）</a></p>
<p><a href="http://nil.csail.mit.edu/6.824/2020/schedule.html">2020课程安排官方链接（含实验）</a></p>
<p>起初读到Mapreduce论文的时候还在12月初，想要去总结但一拖拖到现在，接下来我将对Mapreduce论文的学习进行一些总结：</p>
<h1 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h1><p>一致性就是用来定义操作行为的概念。从性能和容错的角度来说，我们通常会有多个副本。在一个非分布式系统中，你通常只有一个服务器，一个表单。虽然不是绝对，但是通常来说对于put&#x2F;get的行为不会有歧义。直观上来说，put就是更新这个表单，get就是从表单中获取当前表单中存储的数据。但是在一个分布式系统中，由于复制或者缓存，数据可能存在于多个副本当中，于是就有了多个不同版本的key-value对。假设服务器有两个副本，那么他们都有一个key-value表单，两个表单中key 1对应的值都是20。</p>
<p>之后会发送给第二台服务器，因为相同的put请求需要发送给两个副本，这样这两个副本才能保持同步。但是就在客户端准备给第二台服务器发送相同请求时，这个客户端故障了，可能是电源故障或者操作系统的bug之类的。所以，现在我们处于一个不好的状态，我们发送了一个put请求，更新了一个副本的值是21，但是另一个副本的值仍然是20。</p>
<p>如果现在某人通过get读取key为1的值，那么他可能获得21，也可能获得20，取决于get请求发送到了哪个服务器。即使规定了总是把请求先发送给第一个服务器，那么我们在构建容错系统时，如果第一台服务器故障了，请求也会发给第二台服务器。所以不管怎么样，总有一天你会面临暴露旧数据的风险。很可能是这样，最开始许多get请求都得到了21，之后过了一周突然一些get请求得到了一周之前的旧数据（20）。所以，这里不是很一致。并且，如果我们不小心的话，这个场景是可能发生的，所以，我们需要确定put&#x2F;get操作的一些规则。</p>
<p>实际上，对于一致性有很多不同的定义。有一些非常直观，比如说get请求可以得到最近一次完成的put请求写入的值。这种一般也被称为强一致（Strong Consistency）。弱一致是指，不保证get请求可以得到最近一次完成的put请求写入的值。尽管有很多细节的工作要处理，强一致可以保证get得到的是put写入的最新的数据；而很多的弱一致系统不会做出类似的保证。所以在一个弱一致系统中，某人通过put请求写入了一个数据，但是你通过get看到的可能仍然是一个旧数据，而这个旧数据可能是很久之前写入的。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/consistency.png?raw=true" alt="一致性"></p>
<h1 id="Mapreduce论文"><a href="#Mapreduce论文" class="headerlink" title="Mapreduce论文"></a>Mapreduce论文</h1><h2 id="Mapreduce框架"><a href="#Mapreduce框架" class="headerlink" title="Mapreduce框架"></a>Mapreduce框架</h2><p>MapReduce的思想是：应用程序设计人员和分布式运算的使用者，只需要写简单的Map函数和Reduce函数，而不需要知道任何有关分布式的事情，MapReduce框架会处理剩下的事情。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/mapreduce.png?raw=true" alt="Mapreduce框架"></p>
<p>Map函数以文件作为输入，文件是整个输入数据的一部分。Map函数的输出是一个key-value对的列表。假设我们在实现一个最简单的MapReduce Job：单词计数器。它会统计每个单词出现的次数。在这个例子中，Map函数会输出key-value对，其中key是单词，而value是1。Map函数会将输入中的每个单词拆分，并输出一个key-value对，key是该单词，value是1。最后需要对所有的key-value进行计数，以获得最终的输出。所以，假设输入文件1包含了单词a和单词b，Map函数的输出将会是key&#x3D;a，value&#x3D;1和key&#x3D;b，value&#x3D;1。第二个Map函数只从输入文件2看到了b，那么输出将会是key&#x3D;b，value&#x3D;1。第三个输入文件有一个a和一个c。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/mapreduce_execution.png?raw=true" alt="Mapreduce执行过程"></p>
<p>我们对所有的输入文件都运行了Map函数，并得到了论文中称之为中间输出（intermediate output），也就是每个Map函数输出的key-value对。<br>运算的第二阶段是运行Reduce函数。MapReduce框架会收集所有Map函数输出的每一个单词的统计。比如说，MapReduce框架会先收集每一个Map函数输出的key为a的key-value对。收集了之后，会将它们提交给Reduce函数。</p>
<p>之后会收集所有的b。这里的收集是真正意义上的收集，因为b是由不同计算机上的不同Map函数生成，所以不仅仅是数据从一台计算机移动到另一台（如果Map只在一台计算机的一个实例里，可以直接通过一个RPC将数据从Map移到Reduce）。我们收集所有的b，并将它们提交给另一个Reduce函数。这个Reduce函数的入参是所有的key为b的key-value对。对c也是一样。所以，MapReduce框架会为所有Map函数输出的每一个key，调用一次Reduce函数。</p>
<p>Job：整个MapReduce计算称为Job</p>
<p>Task：每一次MapReduce调用称为Task</p>
<h2 id="Map函数和Reduce函数"><a href="#Map函数和Reduce函数" class="headerlink" title="Map函数和Reduce函数"></a>Map函数和Reduce函数</h2><h3 id="Map函数"><a href="#Map函数" class="headerlink" title="Map函数"></a>Map函数</h3><p>入参中，key是输入文件的名字，通常会被忽略，因为我们不太关心文件名是什么，value是输入文件的内容。所以，对于一个单词计数器来说，value包含了要统计的文本，我们会将这个文本拆分成单词。之后对于每一个单词，我们都会调用emit。emit由MapReduce框架提供，并且这里的emit属于Map函数。emit会接收两个参数，其中一个是key，另一个是value。在单词计数器的例子中，emit入参的key是单词，value是字符串“1”。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/map.png?raw=true" alt="Map函数"></p>
<h3 id="Reduce函数"><a href="#Reduce函数" class="headerlink" title="Reduce函数"></a>Reduce函数</h3><p>Reduce函数的入参是某个特定key的所有实例（Map输出中的key-value对中，出现了一次特定的key就可以算作一个实例）。所以Reduce函数也是使用一个key和一个value作为参数，其中value是一个数组，里面每一个元素是Map函数输出的key的一个实例的value。对于单词计数器来说，key就是单词，value就是由字符串“1”组成的数组，所以，我们不需要关心value的内容是什么，我们只需要关心value数组的长度。Reduce的emit函数只接受一个参数value，这个value会作为Reduce函数入参的key的最终输出。所以，对于单词计数器，我们会给emit传入数组的长度。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/reduce.png?raw=true" alt="Reduce函数"></p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="Shuffle过程"><a href="#Shuffle过程" class="headerlink" title="Shuffle过程"></a>Shuffle过程</h3><p>Mapreduce框架中提到的从Map函数到Reduce函数的过程就是<strong>shuffle</strong>，根据课程中的讲解，这个过程如mapreduce图所示<strong>本质是从行存储到列存储的转换</strong>，也是mapreduce整个过程代价最大的部分</p>
<p>这里的shuffle的重点是，这里实际上可能会有大量的网络通信。假设你在进行排序，排序的输入输出会有相同的大小。这样，如果你的输入是10TB，为了能排序，你需要将10TB的数据在网络上移动，并且输出也会是10TB，所以这里有大量的数据。这可能发生在任何MapReduce job中，尽管有一些MapReduce job在不同阶段的数据没有那么大。之前有人提过，想将Reduce的输出传给另一个MapReduce job，而这也是人们常做的事情。在一些场景中，Reduce的输出可能会非常巨大，比如排序，比如网页索引器。10TB的输入对应的是10TB的输出。所以，Reduce的输出也会存储在GFS上。但是Reduce只会生成key-value对，MapReduce框架会收集这些数据，并将它们写入到GFS的大文件中。</p>
<h3 id="Mapreduce-GFS"><a href="#Mapreduce-GFS" class="headerlink" title="Mapreduce+GFS"></a>Mapreduce+GFS</h3><p>GFS是一个共享文件服务，并且它也运行在MapReduce的worker集群的物理服务器上。GFS会自动拆分你存储的任何大文件，并且以64MB的块存储在多个服务器之上。所以，如果你有了10TB的网页数据，你只需要将它们写入到GFS，甚至你写入的时候是作为一个大文件写入的，GFS会自动将这个大文件拆分成64MB的块，并将这些块平均的分布在所有的GFS服务器之上，而这是极好的，这正是我们所需要的。如果我们接下来想要对刚刚那10TB的网页数据运行MapReduce Job，数据已经均匀的分割存储在所有的服务器上了。如果我们有1000台服务器，我们会启动1000个Map worker，每个Map worker会读取1&#x2F;1000输入数据。这些Map worker可以并行的从1000个GFS文件服务器读取数据，并获取巨大的读取吞吐量，也就是1000台服务器能提供的吞吐量。</p>
<h3 id="论文补充"><a href="#论文补充" class="headerlink" title="论文补充"></a>论文补充</h3><p>The master keeps several data structures. For each map task and reduce task, it stores the state (idle, in-progress, or completed), and the identity of the worker machine (for non-idle tasks).</p>
<p>The master pings every worker periodically. If no re- sponse is received from a worker in a certain amount of time, the master marks the worker as failed.</p>
<p>The master runs an internal HTTP server and exports a set of status pages for human consumption.</p>
<h3 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h3><p><a href="http://nil.csail.mit.edu/6.824/2020/labs/lab-mr.html">6.824lab1链接</a></p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/07/23/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>copy-on-write机制</title>
    <url>/2023/02/17/copy-on-write%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h1 id="copy-on-write机制"><a href="#copy-on-write机制" class="headerlink" title="copy-on-write机制"></a>copy-on-write机制</h1><p><a href="https://juejin.cn/post/6844903702373859335">参考链接</a></p>
<p>写时复制（Copy-on-write，COW），有时也称为隐式共享（implicit sharing）。COW 将复制操作推迟到第一次写入时进行：在创建一个新副本时，不会立即复制资源，而是共享原始副本的资源；当修改时再执行复制操作。通过这种方式共享资源，可以显著减少创建副本时的开销，以及节省资源；同时，资源修改操作会增加少量开销。</p>
<h1 id="linux下的fork函数和exec函数"><a href="#linux下的fork函数和exec函数" class="headerlink" title="linux下的fork函数和exec函数"></a>linux下的fork函数和exec函数</h1><p>在说明Linux下的copy-on-write机制前，首先要知道两个函数：fork()和exec()</p>
<p>需要注意的是exec()并不是一个特定的函数, 它是一组函数的统称, 它包括了execl()、execlp()、execv()、execle()、execve()、execvp()</p>
<p>fork是类Unix操作系统上<strong>创建进程</strong>的主要方法，fork用于创建子进程(等同于当前进程的副本)，新的进程要通过老的进程复制自身得到，Linux的进程都通过<strong>init进程或init的子进程</strong>fork(vfork)出来的</p>
<p>从上面我们已经知道了fork会创建一个子进程。子进程的是父进程的副本。</p>
<p>exec函数的作用就是：装载一个新的程序（可执行映像）覆盖当前进程内存空间中的映像，从而执行不同的任务，exec系列函数在执行时会直接替换掉当前进程的地址空间。</p>
<h1 id="copy-on-write实现原理"><a href="#copy-on-write实现原理" class="headerlink" title="copy-on-write实现原理"></a>copy-on-write实现原理</h1><h2 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h2><p>既然很多时候复制给子进程的数据是无效的，于是就有了Copy On Write这项技术了，原理也很简单：</p>
<p>fork创建出的子进程，<strong>与父进程共享内存空间</strong>。也就是说，如果<strong>子进程不对内存空间进行写入操作的话，内存空间中的数据并不会复制给子进程</strong>，这样创建子进程的速度就很快了！(不用复制，直接引用父进程的物理空间)。<br>并且如果在fork函数返回之后，子进程<strong>第一时间</strong>exec一个新的可执行映像，那么也不会浪费时间和内存空间了。</p>
<p>另外表达：在fork之后exec之前两个进程用的是相同的<strong>物理空间（内存区）</strong>，子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个，当<strong>父子进程中有更改相应段的行为</strong>发生时，再为子进程相应的段分配物理空间</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/copy-on-write_implement.png?raw=true" alt="实现原理"></p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>fork()之后，kernel把父进程中所有的内存页的权限都设为<strong>read-only</strong>，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发<strong>页异常中断（page-fault）</strong>，陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：减少不必要的资源分配，节省宝贵的物理内存。</p>
<p>缺点：如果在子进程存在期间发生了大量写操作，那么会频繁地产生页面错误，不断陷入内核，复制页面。这反而会降低效率。</p>
<h2 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h2><p><strong>语言中的应用:</strong><br>相比于传统的深层复制，能带来很大性能提升。比如 C++ 98 标准下的 std::string 就采用了写时复制的实现：</p>
<pre><code>std::string x(&quot;Hello&quot;);
std::string y = x;  // x、y 共享相同的 buffer
y += &quot;, World!&quot;;    // 写时复制，此时 y 使用一个新的 buffer
                    // x 依然使用旧的 buffer
</code></pre>
<p>Golang、PHP 中的 string、array 也是写时复制。在修改这些类型时，如果其引用计数非零，则会复制一个副本。因此我们在 golang、php 中可以将字符串、数组当作值类型（values type）进行传递，即不会有传值复制的开销，也能保证其 immutable 的特性。</p>
<p><strong>文件系统中的应用：</strong><br>Copy-on-write在对数据进行修改的时候，不会直接在原来的数据位置上进行操作，而是重新找个位置修改，这样的好处是一旦系统突然断电，重启之后不需要做Fsck。好处就是能保证数据的完整性，掉电的话容易恢复。</p>
<p>比如说：要修改数据块A的内容，先把A读出来，写到B块里面去。如果这时候断电了，原来A的内容还在！</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>vm-ft论文总结</title>
    <url>/2023/02/27/vm-ft%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="容错与复制"><a href="#容错与复制" class="headerlink" title="容错与复制"></a>容错与复制</h1><p>这节课首先谈论了容错（Fault-Tolerance）技术中的<strong>复制（Replication）技术</strong></p>
<p>目前我知道的分布式存储手段有<strong>复制（Replication）</strong>和<strong>分片（Sharding）</strong>，复制技术主要用于解决<strong>fail-stop故障</strong>，比如 CPU 过热而关闭、主机或者网络断电、硬盘空间耗尽等问题。但是复制不能处理一些<strong>相关联（correlated，主副本机器会同时存在）的问题和软件中的bug和硬件设计中的缺陷</strong>。</p>
<p>至于是否值得使用复制技术，需要对业务场景和所需费用考量，是否真的需要进行 Replica。比如银行数据就需要多备份，而课程网站可能并不需要。</p>
<h1 id="VM-FT论文总结"><a href="#VM-FT论文总结" class="headerlink" title="VM-FT论文总结"></a>VM-FT论文总结</h1><h2 id="状态转移和复制状态机"><a href="#状态转移和复制状态机" class="headerlink" title="状态转移和复制状态机"></a>状态转移和复制状态机</h2><p>论文首先介绍了两种进行状态备份的方式：</p>
<p><strong>状态转移（State transfer）</strong></p>
<p>Primary和Backup互为副本，Primary将自己完整状态，比如说内存中的内容，拷贝并发送给Backup。Backup会保存收到的<strong>最近一次状态</strong>。每过一会，Primary就会对自身的内存做一大份拷贝，并通过网络将其发送到Backup。为了提升效率，你可以想到每次同步只发送上次同步之后变更了的内存。</p>
<p><strong>复制状态机（Replicated State Machine）</strong></p>
<p>将服务器看作是一个具有确定性状态的状态机，只要给定相同初始状态和同样顺序的确定输入，就能保持同样的状态。同步的是<strong>外部的事件 &#x2F; 操作 &#x2F; 输入</strong>；同步的内容通常较小，但是依赖主机的一些特性：比如指令执行的确定性（deterministic）。而在物理机上保证确定性很难，但是在 VM 上就简单的多，由于 hypervisor 有对 VM 有完全的控制权，因此可以通过某些手段来额外同步某些不确定性输入（比如类似随机数、系统时钟等）。</p>
<p>Replicated State Machine 需要机器为<strong>单核</strong>，因为在多核机器上，指令的执行顺序本身是不确定的。那对于多核机器如何做同步？State Transfer </p>
<h2 id="同步状态的层级"><a href="#同步状态的层级" class="headerlink" title="同步状态的层级"></a>同步状态的层级</h2><p>应用层（Application state）。如 GFS，更为高效，只需要发送高维操作即可，缺点是需要在应用层进行容错。<br>机器层（Machine level）。可以让运行在服务器上的应用无需改动而获取容错能力。但需要细粒度的同步机器事件（中断、DMA）；并且需要修改机器底层实现以发送这些事件。<br>而 VM-FT 选择了后者，能力更强大，但也做出了更多牺牲。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/vm-ft_configuration.png?raw=true" alt="vm-ft配置"></p>
<p>VM-FT 系统使用一个额外的虚拟层 <strong>VMMonitor</strong>（ hypervisor &#x2F; (VMM)Virtual Machine Monitor），当 client 请求到达 Primary 时，VMMonitor 一方面向本机转发请求、一方面向 Backup 的 VMMonitor 同步请求。处理完请求得到结果时，Primary 的 VMMonitor 会回复 Client，而 Backup 的 VMMonitor 会丢弃 Backup 产生的回复。</p>
<p>使用两种方法来检测 Primary 和 Backup 的健康状况：</p>
<p>· 和 Primary&#x2F;Backup 进行心跳<br>· 监控<strong>logging channel</strong></p>
<p>VMware FT论文中将<strong>Primary到Backup之间同步的数据流的通道称之为Log Channel</strong></p>
<h2 id="主从切换"><a href="#主从切换" class="headerlink" title="主从切换"></a>主从切换</h2><p>当Primary宕机时，Backup虚机会上线（Go Alive），Backup的VMM会让Backup自由执行，而不是受来自于Primary的事件驱动。Backup的VMM会在网络中做一些处理（猜测是发GARP），让后续的客户端请求发往Backup，而不是Primary。同时，Backup的VMM不再会丢弃Backup的输出。然后利用 VMotion 的技术在和新 Primary 共享外存的地方启动一个副本，并且建立日志通道。</p>
<p>一种可能是，Backup 声称具有 Primary 的 MAC 地址，然后让 ARP 缓存表过期，就将打向某个 IP 的流量从 Primary 切换到了 Backup。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/wm-ft_workflow%20.png?raw=true" alt="vm-ft工作原理"></p>
<h2 id="非确定性事件"><a href="#非确定性事件" class="headerlink" title="非确定性事件"></a>非确定性事件</h2><p>所谓非确定性事件就是不由当前内存直接决定的指令。如果不够小心，这些指令在Primary和Backup的运行结果可能会不一样。</p>
<p>非确定性事件主要包括以下三种：</p>
<p>·<strong>客户端输入</strong></p>
<p>输入实际上是指接收到了一个<strong>网络数据包</strong>，网络数据包有两部分，一个是数据包中的数据，另一个是提示<strong>数据包送达的中断</strong>。当网络数据包送达时，通常网卡的DMA（Direct Memory Access）会将网络数据包的内容拷贝到内存，之后触发一个中断。</p>
<p><strong>·怪异指令</strong></p>
<p>随机数生成器，获取当前时间的指令，获取计算机的唯一ID</p>
<p><strong>·多CPU并发</strong></p>
<p>当服务运行在多CPU上时，指令在不同的CPU上会交织在一起运行，进而产生的指令顺序是不可预期的</p>
<p>所有的事件都需要通过<strong>Log Channel</strong>，从Primary同步到Backup，对于不确定性操作，需要保留充足的信息到日志通道中，以使 Backup 可以进行同样的状态改变，并且产生同样输出。发送到日志通道的事件信息包括：<strong>事件发生时的指令序号、日志条目的类型、数据</strong></p>
<p><strong>如何防止backup执行快于primary？</strong><br>VMware FT会维护一个来自于Primary的<strong>Log条目的等待缓冲区</strong>，如果缓冲区为空，Backup是不允许执行指令的。如果缓冲区不为空，那么它可以根据Log的信息知道Primary对应的指令序号，并且会强制Backup虚机最多执行指令到这个位置。</p>
<h2 id="输出控制（OutPut-rule）"><a href="#输出控制（OutPut-rule）" class="headerlink" title="输出控制（OutPut rule）"></a>输出控制（OutPut rule）</h2><p>在Primary收到客户端请求并生成数据后，VMM不会无条件转发这个输出给客户端。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/FT_protocol.png?raw=true" alt="FT_protocol"></p>
<p><strong>Primary的VMM会等到之前的Log条目都被Backup虚机确认收到了才将输出转发给客户端</strong>。所以，包含了客户端输入的Log条目，会从Primary的VMM送到Backup的VMM，Backup的VMM不用等到Backup虚机实际执行这个输入，就会发送一个表明收到了这条Log的ACK报文给Primary的VMM。当Primary的VMM收到了这个ACK，才会将Primary虚机生成的输出转发到网络中。</p>
<p><strong>核心：确保在客户端看到对于请求的响应时，Backup虚机一定也看到了对应的请求</strong></p>
<h2 id="Test-and-Set服务"><a href="#Test-and-Set服务" class="headerlink" title="Test-and-Set服务"></a>Test-and-Set服务</h2><p>当Primary和Backup都在运行，但是它们之间的网络出现了问题，同时它们各自又能够与一些客户端通信。<strong>产生Split Brain现象</strong>，这篇论文的办法是：向一个<strong>外部的第三方权威机构求证，来决定Primary还是Backup允许上线</strong>。</p>
<p>Test-and-Set服务不运行在Primary和Backup的物理服务器上，VMware FT需要通过网络支持Test-and-Set服务。Test-and-Set请求会设置<strong>标志位</strong>，并且返回旧的值。Primary和Backup都需要获取Test-and-Set标志位，当第一个请求送达时，Test-and-Set服务会说，这个标志位之前是0，现在是1。第二个请求送达时，Test-and-Set服务会说，标志位已经是1了，你不允许成为Primary。</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>test</title>
    <url>/2022/07/23/test/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>故障模型</title>
    <url>/2023/02/12/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="故障模型"><a href="#故障模型" class="headerlink" title="故障模型"></a>故障模型</h1><p>最近在学习论文VM-FT，涉及到故障类型fail-stop failure，故在此对故障类型进行总结</p>
<h2 id="fault-error-and-failure"><a href="#fault-error-and-failure" class="headerlink" title="fault, error and failure"></a>fault, error and failure</h2><p>·Fault: 在系统中某一个步骤偏离正确的执行叫做一个fault, 比如内存写入错误, 但是如果内存是ECC的那么这个fault可以立刻被修复, 就不会导致error。</p>
<p>·Error: 如果一个fault没能在结果影响到整个系统状态之前被修复, 结果导致系统的状态错误, 那么这就是一个error, 比如不带ECC的内存导致一个计算结果错误。</p>
<p>·Failure: 如果一个系统的error没能在错误状态传递给其它节点之前被修复, 换句话说error被扩散出去, 这就是一个failure.</p>
<p>所以他们的关系是fault导致error, error导致failure. 在分布式系统中, 每个节点很难确定其它节点内部的状态, 通常只能通过和其他节点的交互监测到failure. 接下来我们所说的故障一般都是指failure.</p>
<h2 id="分布式系统故障模型"><a href="#分布式系统故障模型" class="headerlink" title="分布式系统故障模型"></a>分布式系统故障模型</h2><p>Byzantine failures: 这是最难处理的情况, 一个节点压根就不按照程序逻辑执行, 对它的调用会返回给你随意或者混乱的结果. 要解决拜占庭式故障需要有同步网络, 并且故障节点必须小于1&#x2F;3或者消息传递过程中不可篡改，通常只有某些特定领域才会考虑这种情况通过高冗余来消除故障。</p>
<p>Crash-recovery failures: 它比byzantine类故障加了一个限制, 那就是节点总是按照程序逻辑执行, 结果是正确的. 但是不保证消息返回的时间. 原因可能是crash后重启了, 网络中断了, 异步网络中的高延迟. 对于crash的情况还要分健忘(amnesia)和非健忘的两种情况. 对于健忘的情况, 是指这个crash的节点重启后没有完整的保存crash之前的状态信息, 非健忘是指这个节点crash之前能把状态完整的保存在持久存储上, 启动之后可以再次按照以前的状态继续执行和通信。</p>
<p>Omission failures: 比crash-recovery多了一个限制, 就是一定要非健忘. 有些算法要求必须是非健忘的. 比如最基本版本的Paxos要求节点必须把ballot number记录到持久存储中, 一旦crash, 修复之后必须继续记住之前的ballot number。</p>
<p>Crash failure: Omission failure的特例；在omission failure的基础上，增加了节点停止响应的假设，也即持续性地omission failure。</p>
<p>Crash-stop failures&#x2F;Fail-stop failures: 也叫做crash failure, 它比omission failure多了一个故障发生后要停止响应的要求. 比如一个节点出现故障后立即停止接受和发送所有消息, 或者网络发生了故障无法进行任何通信, 并且这些故障不会恢复. 简单讲, 一旦发生故障, 这个节点 就不会再和其它节点有任何交互. 就像他的名字描述的那样, crash and stop。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/Failure_modes.png?raw=true" alt="故障模型"></p>
<p>Fail-stop failure这个模型，其是在Crash failure模型的基础上增加了故障可检测的假设。回顾我们在第2节中的理解：同步网络和异步网络最大的区别在于故障的可检测性。<br>因此，Fail-stop failure模型本质上是在Crash failure模型的基础上增加了“同步网络”的假设</p>
<h2 id="fail-stop-故障-和-bugs"><a href="#fail-stop-故障-和-bugs" class="headerlink" title="fail-stop 故障 和 bugs"></a>fail-stop 故障 和 bugs</h2><p>简单来说复制能够处理单台计算机的fail-stop故障，如果某些东西出现故障，只是单纯的停止运行，而不是运算出错误结果。 比如电源线、服务器风扇导致CPU过热停止运行、网络等故障。网络隔离场景很有趣，因为从外界来看，这和服务器停止运行毫无区别。</p>
<p>复制不能处理软件中的bug和硬件设计中的缺陷。 如果相同的程序，都计算出错误的结果，那么再多副本也都无法避免。我们也不能期望复制可以处理硬件的漏洞，当硬件有漏洞的时候会计算出错误的结果，至少基于复制这种技术，我们就无能为力了。</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>拜占庭容错--BFT</title>
    <url>/2022/12/25/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%AE%B9%E9%94%99-BFT/</url>
    <content><![CDATA[<h1 id="拜占庭容错系统中的N-gt-x3D-3f-1问题"><a href="#拜占庭容错系统中的N-gt-x3D-3f-1问题" class="headerlink" title="拜占庭容错系统中的N &gt;&#x3D; 3f+1问题"></a>拜占庭容错系统中的<strong>N &gt;&#x3D; 3f+1</strong>问题</h1><p><a href="https://decentralizedthoughts.github.io/start-here/">https://decentralizedthoughts.github.io/start-here/</a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在上面的网站中学习区块链基础知识，昨天从<a href="https://zhuanlan.zhihu.com/p/36000412">https://zhuanlan.zhihu.com/p/36000412</a>看懂了N &gt;&#x3D; 3f+1的证明，在此进行总结：<br><br>解决拜占庭将军问题的共识算法有很多（如PBFT，QU，HQ等），但无论共识算法如何设计，所有的算法都需要遵守一个容忍攻击者数量的限制(这个限制是与某个具体的算法实现无关的)。该限制描述如下：结点总数量为N时，最多只能容纳f个拜占庭故障（叛徒）节点，令N &gt;&#x3D; 3f+1。</p>
<h2 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>quorum（法定人数），所谓quorum指的是做出一次决策至少需要的同意票数量<br><br>liveness（活性）：liveness这个术语来自论文<a href="https://link.zhihu.com/?target=https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf">FLP impossibility</a>。liveness，又称guaranteed termination，就是说共识算法的执行过程中不能卡死，最终能按照算法流程一步步得到执行结果。<br><br>safety（安全性）:safety这个术语同样来自论文FLP impossibility。此处用通俗的话解释一下，所谓安全性又称linearizability，就是说，执行共识算法之后，所有节点的内容能保证一致</p>
<h3 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h3><p>设总结点数为N，作恶的拜占庭节点数为 f，法定人数为Q<br><br>要满足liveness必须有：<br><br>**Q &lt;&#x3D; N-f** <br><br>说明：如果共识算法需要的Q大于N-f，则当f个拜占庭故障节点都主动破坏时，算法必然不能执行下去<br></p>
<p>要满足safety必须有：<br><br><strong>2Q - N &gt; f</strong> <br><br>说明：假设好人的意见分裂了，X个人倾向于方案A，剩余N-f-X个人倾向于方案B。根据safety的定义，坏人要使系统不safety，就要利用自己的f张投票使得方案A和B都能通过：X+f≥Q；N-f-X+f≥Q 。两式相加得证N+f≥2Q 是坏人能作恶的边界条件。</p>
<p>因为除了leader节点之外的好人节点有可能会出现运行异常，对外表现为意见分裂。但好人节点与拜占庭节点最大的不同是，拜占庭节点可能同时支持正反两种观点，而好人节点只可能分裂（有人支持正有人支持反），但不会说两样话（即，既支持正也支持反）</p>
<p>因此：</p>
<p>N+f &lt; 2Q &lt;&#x3D; 2(N-f)<br><br>N &gt; 3f<br><br>if N&#x3D;3f+1 此时Q的最小值为：<br><br>Qmin &#x3D; 2f+1</p>
<p>证毕</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>对于所有的拜占庭将军问题，在不更改假设前提时，无论算法怎么设计，当总结点数为N时，最多只能容忍f个作恶节点(拜占庭故障节点)，使N &gt; 3f + 1，此时Q &gt; 2f + 1</p>
]]></content>
      <tags>
        <tag>共识算法</tag>
      </tags>
  </entry>
  <entry>
    <title>纠删码（Erasure Code）及其演进LRC（Locally Repairable Codes）</title>
    <url>/2023/01/11/%E7%BA%A0%E5%88%A0%E7%A0%81%EF%BC%88Erasure-Code%EF%BC%89%E5%8F%8A%E5%85%B6%E6%BC%94%E8%BF%9BLRC%EF%BC%88Locally-Repairable-Codes%EF%BC%89/</url>
    <content><![CDATA[<h1 id="EC及其演进LRC"><a href="#EC及其演进LRC" class="headerlink" title="EC及其演进LRC"></a>EC及其演进LRC</h1><p>近期因为几门课程作业，阅读了一些论文，在此依次进行总结</p>
<p><a href="https://zhuanlan.zhihu.com/p/69374970">参考链接1</a></p>
<p><a href="https://www.cnblogs.com/tinoryj/p/Erasure-Codes-for-Storage-Systems-Summary.html">参考链接2</a></p>
<p><a href="https://blog.csdn.net/cyq6239075/article/details/105775698">参考链接3</a></p>
<p>如何保证存储可靠性、数据可用性是大规模存储系统的难点和要点。数据冗余是保障存储可靠性、数据可用性的最有效手段。传统的冗余机制主要有副本（Replication）和纠删编码（Erasure Code）</p>
<h2 id="副本（Replication）"><a href="#副本（Replication）" class="headerlink" title="副本（Replication）"></a>副本（Replication）</h2><p>副本是将每个原始数据分块都镜像复制到另一存储介质上，从而保证在原始数据失效后，数据仍然可用并能通过副本数据恢复。多副本策略即将数据存储多个副本（一般是三副本，比如HDFS），当某个副本丢失时，可以通过其他副本复制回来。三副本的磁盘利用率为1&#x2F;3。</p>
<h2 id="纠删编码（EC）"><a href="#纠删编码（EC）" class="headerlink" title="纠删编码（EC）"></a>纠删编码（EC）</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>总数据块 &#x3D; 原始数据块 + 校验块</p>
<p>n &#x3D; k + m</p>
<p>从k个原始数据块中计算出m个校验块</p>
<p>编码只需要乘法和加法，解码需要用高斯消除或矩阵求逆求的方法解一组线性方程。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>在出现硬盘故障后，重建数据非常耗CPU，而且计算一个数据块需要通过网络读出k倍的数据并传输，网络负载成倍增加</p>
<h2 id="局部校验编码LRC（Locally-Repairable-Codes）"><a href="#局部校验编码LRC（Locally-Repairable-Codes）" class="headerlink" title="局部校验编码LRC（Locally Repairable Codes）"></a>局部校验编码LRC（Locally Repairable Codes）</h2><p>局部校验编码：将校验块（parity block）分为全局校验块(global parity)、局部重建校验块(local reconstruction parity)，故障恢复时分组计算。</p>
<p>例子：</p>
<p>P1&#x3D;D1+D2</p>
<p>P2&#x3D;D3+D4</p>
<p>P3&#x3D; D1+D2+ D3+D4</p>
<p>P1、P2是局部校验。P3是全局校验<br><img data-src="https://img-blog.csdnimg.cn/20200426195932950.png" alt="例子"></p>
<p>当仅损坏一个数据块时，可以根据该数据在所在的分组，在组内对该数据块进行重建。损坏一个数据块时的最差情况就是全局校验块损坏，此时需要读全部数据块数据进行重建。</p>
<p>当损坏两个数据块时情况分成组内和组外，不管哪种需要拉取全部数据进行重建，此时采用LRC方法并不能提升性能。</p>
<p>当损坏三块数据时，如果这三个数据块在一个组内，例如P1、D1、D2。此时就无法进行数据重建，虽然我们这里是使用三个校验。</p>
<p>所以LRC并不是100%保证数据不丢，并且还要多占用一部分存储空间</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>消息认证码Message Authentication Code(MAC)</title>
    <url>/2023/03/19/%E6%B6%88%E6%81%AF%E8%AE%A4%E8%AF%81%E7%A0%81Message-Authentication-Code-MAC/</url>
    <content><![CDATA[<p>消息认证码（Message Authentication Code）是一种确认完整性并进行认证的技术</p>
<p>消息认证码的输入为任意长度的<strong>消息</strong>和一个发送者与接收者之间<strong>共享的密钥</strong>，它可以输出固定长度的数据，这个数据称为 MAC 值</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/message_authentication_code.png?raw=true" alt="消息认证码"></p>
<p>个人理解，消息认证码就是：传递一条消息，为了保证这个消息是你本人发的，把这个消息和共享密钥结合得到一个MAC值，同时传递过去，接收方通过接收消息，计算MAC值再与发送<br>方发来的MAC值对比即可验证。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/message_authentication_code_example.png?raw=true" alt="例子"></p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>记hexo配置与部署</title>
    <url>/2022/07/26/%E8%AE%B0hexo%E9%85%8D%E7%BD%AE%E4%B8%8E%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="记hexo配置与部署"><a href="#记hexo配置与部署" class="headerlink" title="记hexo配置与部署"></a>记hexo配置与部署</h1><p>hexo中文文档：<a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a></p>
<hr>
<p>因为官方文档的一点小问题和我对Mac系统环境变量、终端类型等的不熟悉，这个安装过程比较坎坷。关于Git和Node.js的安装比较顺利，我又顺手安装了Homebrew（Mac下的包管理器）。</p>
<hr>
<h2 id="Hexo安装过程中的小问题"><a href="#Hexo安装过程中的小问题" class="headerlink" title="Hexo安装过程中的小问题"></a>Hexo安装过程中的小问题</h2><p>Hexo的安装首先如文档所说出现了EACCES权限错误，解决办法是将npm的<strong>全局</strong>安装包放到新创建的npm-global文件夹，并将npm-global的路径添加到环境变量，问题就出在环境变量的配置，Node.js的文档中提到将npm-global&#x2F;bin添加到环境变量的语句加入到<del>&#x2F;.profile 中，</del>&#x2F;.profile是<strong>bash终端</strong>的环境变量配置文件，而现在Mac系统默认为<strong>zsh终端</strong>，需要将上述语句加入.zshrc文件中，保证在打开终端后npm全局环境变量已经加载。否则，需要每次source ~&#x2F;.profile才可以执行 hexo &lt; command &gt; 命令。经过几个小时的排查最终发现。</p>
<hr>
<h2 id="Hexo常用命令"><a href="#Hexo常用命令" class="headerlink" title="Hexo常用命令"></a>Hexo常用命令</h2><p>hexo n “新博客”  创建新博客</p>
<p>hexo clean      清理hexo缓存</p>
<p>hexo g          生成博客</p>
<p>hexo d          部署博客</p>
]]></content>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>通信模型--同步、异步、部分同步</title>
    <url>/2022/12/25/%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%9E%8B-%E5%90%8C%E6%AD%A5%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E9%83%A8%E5%88%86%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<h1 id="通信模型"><a href="#通信模型" class="headerlink" title="通信模型"></a>通信模型</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>在标准的分布式计算模型中，通信的不确定性被可以控制消息延迟的敌手捕获。通信模型定义了敌手延迟消息的能力的限制。</p>
<p>在同步模型中，存在一些已知的有限时间界限Δ。 对于发送的任何消息，敌手最多可以将其传递延迟Δ。</p>
<p>在异步模型中，对于发送的任何消息，敌手可以将其传递延迟任意有限的时间。 因此，一方面，传递消息的时间没有限制，但另一方面，每条消息最终都必须传递。</p>
<p>部分同步模型（参见<a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf">DLS88</a>）旨在找到这两个模型之间的折中。 假设存在一些已知的有限时间界限 Δ 和一个称为 GST（Global Stabilization Time–全局稳定时间）的特殊事件，使得：敌手必须导致 GST 事件在某个未知的有限时间后最终发生。在时间 x 发送的任何消息必须在时间 Δ+max(x,GST) 之前交付。</p>
<p>在部分同步模型中，系统在GST之前异步运行，在GST之后同步运行</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>对于同步模型：</p>
<p>1.存在一个trade-off问题：有限时间界限Δ过长，造成长时间超时，会降低性能；有限时间界限Δ过短，会造成安全性违规问题。<br>2.假设找到了Δ的sweet spot，想象一个发送者向两个接收者广播一条消息，一个消息在Δ−ε时间后到达，另一个在Δ+ε后到达。在这里，真实世界的行为与模型不同，这可能再次导致安全问题。</p>
<p>对于异步模型：</p>
<p>异步模型的主要问题是该模型中的协议往往更复杂且更难推理。</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>零知识证明ZKP</title>
    <url>/2022/12/30/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8EZKP/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>事务管理与并发控制</title>
    <url>/2022/11/14/%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%8E%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<p>最近看了看《数据库事务处理的艺术》，主要介绍事物原理和并发控制技术，之前有看过一些并发控制的博客，看的一头雾水，这本书相对更清晰一些</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="ACID特性"><a href="#ACID特性" class="headerlink" title="ACID特性"></a>ACID特性</h2><p>（A）原子性：要么成功–Committed，要么失败–Aborted</p>
<p>（C）一致性：<strong>from one valid state to another</strong>。数据在事务的操作下，一直符合“all defined rules”。一个是属于用户的语义所限定的数据一致性，一个是系统级，要求数据库系统符合可串行性（serializability）和可恢复性(recoverability),这两个将在下面具体解释</p>
<p>（I）隔离性：存在多个事务（多个会话中的不同的但同一时间段内运行的事务）同时运行，但他们运行的顺序好像是”serially“</p>
<p>（D）持久性：committed的数据，要能够永久保存</p>
<h2 id="事务的属性"><a href="#事务的属性" class="headerlink" title="事务的属性"></a>事务的属性</h2><h3 id="可串行化"><a href="#可串行化" class="headerlink" title="可串行化"></a>可串行化</h3><p><strong>保证并发的事务调度方式既能满足数据一致性需求，又能提高并发事务的执行效率</strong></p>
<p>如果事务间没有共同的操作对象（R&#x2F;W操作），则事务之间的执行顺序前后置换是没有关系的；但是如果事务间存在共同的操作对象，则事务间先后执行的顺序需要区分；对于存在共同操作对象的多个并发执行的事务，如果其执行等价于某个串行化调度，则这个调度是可串行化调度，具有了可串性化属性。可串性化保证的是多个事务并发时执行顺序要对数据的一致性没有影响。</p>
<p>关于等价，需要几个概念：冲突行为、冲突等价、冲突可串行化<br>冲突可串行化：某个调度“冲突等价”于一个或多个串行调度</p>
<h3 id="可恢复性"><a href="#可恢复性" class="headerlink" title="可恢复性"></a>可恢复性</h3><p>已经提交的事务没有读过被中止的事务的写数据，可恢复性保证多个事务并发调度后期的提交顺序对数据的一致性没有影响</p>
<h3 id="严格性"><a href="#严格性" class="headerlink" title="严格性"></a>严格性</h3><p>保证有冲突动作的并发事务中，先发生写操作的事务提交或中止的操作优先于其他事务。</p>
<h1 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h1><p>Serializable（串行化）<br>以物理上是可串行化的机制保证逻辑上符合串行化调度。一个事务在执行过程中完全看不到其他事务的对数据库所做的更新</p>
<p>Repeatable Read（可重复读）<br>一个事务在执行过程中可以看到其他事务已经提交的新插入的元组，但是不能看到其他事务对已有元组的更新。对于<strong>读出的记录</strong>，添加共享锁直到事务T1结束。其他事务T2对这个记录的修改会一直等待直到事务T1结束。但其他事务允许读取同样的数据。</p>
<p>Read Committed（已提交读）<br>一个事务在执行过程中可以看到<strong>已经提交</strong>的其他事务新插入的元组，能看到<strong>已经提交</strong>的其他事务对已有元组的更新</p>
<p>Read Uncommitted（未提交读）<br>一个事务在执行过程中可以看到<strong>没有提交</strong>的其他事务新插入的元组，能看到<strong>没有提交</strong>的其他事务对已有元组的更新</p>
<h1 id="快照隔离"><a href="#快照隔离" class="headerlink" title="快照隔离"></a>快照隔离</h1><p>使用快照隔离技术的事务中的所有读操作，读到的数据一定是一致的<br>避免了各种<strong>读异常现象</strong><br>如果没有写-写冲突，则会提交成功。不会发生读-写、写-读冲突<br>从事务开始时，处于<strong>当时的并发事务的状态（快照）</strong>被保存，利用这个快照可以判断本事务和其他事务之间启动的先后顺序，事务的读写情况。</p>
<p>快照隔离是MVCC技术的一种实现方式，MVCC技术的本质，是为每个对象在写操作发生时，生成一个新的版本；在读操作发生时，读出最近的一个版本。<br>并发事务同时写一个数据项，要遵循“First-Committer-Wins”,并发的同时写同一个数据项的事务只能有一个成功，另外一个必须回滚，相当于<strong>并发不存在</strong>，解决了写-写冲突。<br>存在写偏序问题，不能保证数据的一致性。<br>阅读进阶GSI–《Database Replication Using Generalized Snapshot Isolation》、PCSI、《Generalized Snapshot Isolation and a Prefix-Consistent Implementation》</p>
<h1 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h1><h2 id="并发控制的实现策略"><a href="#并发控制的实现策略" class="headerlink" title="并发控制的实现策略"></a>并发控制的实现策略</h2><h3 id="乐观（OCC）"><a href="#乐观（OCC）" class="headerlink" title="乐观（OCC）"></a>乐观（OCC）</h3><h3 id="悲观（PCC）"><a href="#悲观（PCC）" class="headerlink" title="悲观（PCC）"></a>悲观（PCC）</h3><h2 id="并发控制的实现技术"><a href="#并发控制的实现技术" class="headerlink" title="并发控制的实现技术"></a>并发控制的实现技术</h2><h3 id="时间戳（TO）"><a href="#时间戳（TO）" class="headerlink" title="时间戳（TO）"></a>时间戳（TO）</h3><ul>
<li>写-读冲突 事务早于写操作，读要回滚；事务晚于写操作，读不受影响</li>
<li>读-写冲突 读前写后回滚写</li>
<li>写-写冲突 新写回滚</li>
<li>改进：Thomas写法则</li>
</ul>
<h3 id="基于有效性检查的并发控制方法"><a href="#基于有效性检查的并发控制方法" class="headerlink" title="基于有效性检查的并发控制方法"></a>基于有效性检查的并发控制方法</h3><p>分为：读阶段、有效性检查阶段、写阶段<br>读阶段先对局部变量进行修改（本地缓存），有效性检查，将局部变量复制到数据库中</p>
<h3 id="Commitment-ordering-CO"><a href="#Commitment-ordering-CO" class="headerlink" title="Commitment ordering(CO)"></a>Commitment ordering(CO)</h3><h3 id="串行化图形检测"><a href="#串行化图形检测" class="headerlink" title="串行化图形检测"></a>串行化图形检测</h3><h3 id="两阶段封锁（2PL）"><a href="#两阶段封锁（2PL）" class="headerlink" title="两阶段封锁（2PL）"></a>两阶段封锁（2PL）</h3><ul>
<li>2PL</li>
<li>S2PL<br>事务持有的排他锁必须在事务提交后才能释放</li>
<li>SS2PL<br>事务提交之前不得释放任何锁</li>
</ul>
<h3 id="多版本并发控制技术（MVCC）"><a href="#多版本并发控制技术（MVCC）" class="headerlink" title="多版本并发控制技术（MVCC）"></a>多版本并发控制技术（MVCC）</h3><ul>
<li>多版本时间戳排序</li>
<li>多版本两阶段封锁协议</li>
<li>基于MVCC的可串行化快照隔离并发控制方法（SSI）<br>SSI&#x3D; SS2PL+MVCC(+SI)+SIREAD锁<br>根据三种依赖关系：读写、写读、写写画并发事务依赖图</li>
</ul>
<h3 id="基于索引的并发控制技术"><a href="#基于索引的并发控制技术" class="headerlink" title="基于索引的并发控制技术"></a>基于索引的并发控制技术</h3><ul>
<li>谓词锁</li>
</ul>
<h1 id="日志技术与恢复子系统"><a href="#日志技术与恢复子系统" class="headerlink" title="日志技术与恢复子系统"></a>日志技术与恢复子系统</h1>]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Paxos原理</title>
    <url>/2023/04/04/Paxos%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="Paxos共识协议"><a href="#Paxos共识协议" class="headerlink" title="Paxos共识协议"></a>Paxos共识协议</h1><p>Paxos就是一个在<strong>异步通信</strong>环境，并容忍在只有<strong>多数派</strong>机器存活的情况下，仍然能完成一个一致性写入的协议</p>
<p>学习过程比较痛苦，multi-Paxos根本看不懂…以后有机会再补充</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="http://dinghao.li/2018/12/Paxos/">共识算法系列：Paxos&#x2F;Multi-Paxos算法关键点综述、优缺点总结</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI4NDMyNTU2Mw==&mid=2247483695&idx=1&sn=91ea422913fc62579e020e941d1d059e#rd">微信自研生产级paxos类库PhxPaxos实现原理介绍</a><br><a href="https://zhuanlan.zhihu.com/p/21438357">Paxos理论介绍(1): 朴素Paxos算法理论推导与证明</a></p>
<h2 id="Paxos算法基本概念"><a href="#Paxos算法基本概念" class="headerlink" title="Paxos算法基本概念"></a>Paxos算法基本概念</h2><p>Paxos的目标——<strong>“确定一个值”、“确定多个值”、“有序的确定多个值”</strong><br>Paxos协议中的角色包括：<strong>Acceptor、Proposer、Learner、State machine</strong><br>Proposer——提出提议；Acceptor——接受提议；Learner——做instance对齐</p>
<p>Proposer只需要与<strong>多数派</strong>的Acceptor交互，即可完成一个值的确定，但一旦这个值被确定下来后，无论Proposer再发起任何值的写入，Data数据都不会再被修改。Chosen value即是被确定的值，永远不会被修改。 </p>
<p><strong>有序的确定多个值</strong>：<br>只要我们通过paxos完成一个<strong>多机一致的有序的操作系列</strong>，就能保证Paxos算法的一致性：</p>
<p>1 给实例一个编号，定义为i，i从0开始，只增不减，由本机器生成，不依赖网络<br>2 我们保证一台机器任一时刻只能有一个实例在工作<br>3 当编号为i的实例获知已经确定好一个值之后，这个实例将会被销毁，进而产生一个编号为i+1的实例</p>
<p><strong>实例的对齐</strong>：<br>回去询问别的机器的相同编号的实例<br>如果这个实例已经被销毁了，那说明值已经确定好了，直接把这个值拉回来写到当前实例里面，直接由Learner直接学习得到即可。</p>
<p><strong>状态机</strong><br>状态机必须记录下来输入过的最大实例编号<br><strong>启动重放</strong>：把这些chosen value一个一个输入到状态机，那么状态机的状态就会更新到y了</p>
<h2 id="朴素Paxos算法"><a href="#朴素Paxos算法" class="headerlink" title="朴素Paxos算法"></a>朴素Paxos算法</h2><p>个人理解朴素Paxos算法就是做一个instance中值的确定的算法过程。</p>
<p>其中包括三个投票的约束，通过反证法可以证明得到一致性结论，比较重要的是MaxVote的定义</p>
<p>问题：为什么需要多轮投票？</p>
<h2 id="Multi-Paxos算法"><a href="#Multi-Paxos算法" class="headerlink" title="Multi-Paxos算法"></a>Multi-Paxos算法</h2><p>暂时没看懂</p>
]]></content>
      <tags>
        <tag>共识算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Exponential backoff--指数补偿</title>
    <url>/2023/05/02/Exponential-backoff-%E6%8C%87%E6%95%B0%E8%A1%A5%E5%81%BF/</url>
    <content><![CDATA[<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://en.wikipedia.org/wiki/Exponential_backoff">wiki百科</a><br><a href="http://note.huangz.me/algorithm/arithmetic/exponential-backoff.html">指数补偿 —— Exponential backoff</a></p>
<h2 id="指数补偿"><a href="#指数补偿" class="headerlink" title="指数补偿"></a>指数补偿</h2><p>指数补偿指的是，在执行事件时，通过反馈，逐渐降低某个过程的速率，从而最终<strong>找到一个合适的速率</strong>（来处理事件）。</p>
<p>指数补偿通常用于网络和传输协议，比如在进行网络连接时，如果第一次请求失败，那么可以等待 t1之后重试，如果再次请求还是失败，那么等待 t2之后重试。</p>
<p>重试可以一直继续下去，或者等待次数或等待时间超过特定值为止。</p>
<p>等待的时间 tn可以是随机选择，也可以随着重试的次数而逐渐加大，诸如此类。</p>
<p>指数退避算法是闭环控制系统的一种形式，可降低受控过程响应不良事件的速率。例如，如果智能手机应用程序无法连接到其服务器，它可能会在 1 秒后重试，如果再次失败，则在 2 秒后，然后 4 等。每次暂停都乘以固定数量（在此情况 2)。在这种情况下，不利事件是无法连接到服务器。不良事件的其他示例包括网络流量冲突、来自服务的错误响应或降低速率的明确请求（即“回退”）。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>《UNIX 环境高级编程，第二版》（APUE，2E） 16.4 节提供了一个带重试的 socket 连接程序， 如果连接失败， 那么程序就睡眠一段时间再尝试， 每失败一次睡眠的时间就延长一些：</p>
<pre><code>#include &quot;apue.h&quot;
#include &lt;sys/socket.h&gt;

#define MAXSLEEP 128

int connect_retry(int sockfd, const struct sockaddr *addr, socklen_talen)
&#123;
int nsec;

for (nsec = 1; nsec &lt; MAXSLEEP; nsec &lt;&lt;=1) &#123;
    if (connect(sockfd, addr, alen) == 0) &#123;
        // connect accepted.
        return 0;
    &#125;
    if (nsec &lt;= MAXSLEEP/2)
        sleep(nsec);
    &#125;

    return -1;
&#125;
</code></pre>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-futex</title>
    <url>/2023/05/18/linux-futex/</url>
    <content><![CDATA[<h1 id="Futex"><a href="#Futex" class="headerlink" title="Futex"></a>Futex</h1><p> futex：a sort of fast, user-space mutual exclusion primitive.</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.jianshu.com/p/d534f6c1fc5d">futex机制介绍</a><br><a href="https://zhuanlan.zhihu.com/p/454244967">内核实现大致逻辑</a></p>
<h2 id="机制介绍"><a href="#机制介绍" class="headerlink" title="机制介绍"></a>机制介绍</h2><p>Futex是一种用户态和内核态混合的同步机制。首先，同步的进程间通过mmap共享一段内存，futex变量就位于这段共享的内存中且操作是原子的，<strong>当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex,而不用再执行系统调用了</strong>。当通过访问futex变量告诉进程有竞争发生，则还是得执行系统调用去完成相应的处理(wait 或者 wake up)。简单的说，futex就是通过在用户态的检查，（motivation）如果了解到没有竞争就不用陷入内核了，大大提高了low-contention时候的效率</p>
<h3 id="为什么要有futex，他解决什么问题？何时加入内核的？"><a href="#为什么要有futex，他解决什么问题？何时加入内核的？" class="headerlink" title="为什么要有futex，他解决什么问题？何时加入内核的？"></a>为什么要有futex，他解决什么问题？何时加入内核的？</h3><p>经研究发现，很多同步是无竞争的，即某个进程进入互斥区，到再从某个互斥区出来这段时间，常常是没有进程也要进这个互斥区或者请求同一同步变量的。但是在这种情况下，这个进程也要陷入内核去看看有没有人和它竞争，退出的时侯还要陷入内核去看看有没有进程等待在同一同步变量上。这些不必要的系统调用(或者说内核陷入)造成了大量的性能开销。为了解决这个问题，Futex就应运而生。</p>
<h2 id="futex-wait-和futex-wake"><a href="#futex-wait-和futex-wake" class="headerlink" title="futex_wait 和futex_wake"></a>futex_wait 和futex_wake</h2><p>总地来说，futex 包含两种基本操作（futex_op）：futex_wait 和futex_wake ：</p>
<p><strong>FUTEX_WAIT</strong> 判断保存在地址addr 的值是否等于val，如果等于，则将当前线程休眠，不等于则返回错误码EWOULDBLOCK。</p>
<p><strong>FUTEX_WAKE</strong> 则是唤醒在地址addr上数量为val个线程</p>
<p>uaddr 和 val 是futex 最重要的两个变量，uaddr 是一个4 字节大小值（futex word）的地址，这个地址一般通过共享内存由多个进（线）程共享，<strong>每个进（线）程在进入futex()后将判断该地址的值和自己期望的值val （expected value）是否相同</strong></p>
<p><strong>具体实现步骤见上文链接</strong></p>
]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>自旋锁——spinlock</title>
    <url>/2023/06/08/%E8%87%AA%E6%97%8B%E9%94%81%E2%80%94%E2%80%94spinlock/</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/cxuanBlog/p/11679883.html">参考链接</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>由于在多处理器环境中某些资源的有限性，有时需要互斥访问(mutual exclusion)，这时候就需要引入锁的概念，只有获取了锁的线程才能够对资源进行访问，由于多线程的核心是CPU的时间分片，所以同一时刻只能有一个线程获取到锁。那么就面临一个问题，那么没有获取到锁的线程应该怎么办？</p>
<p>通常有两种处理方式：<br>一种是没有获取到锁的线程就一直循环等待判断该资源是否已经释放锁，这种锁叫做<strong>自旋锁</strong>，它不用将线程阻塞起来(NON-BLOCKING)；<br>还有一种处理方式就是把自己阻塞起来，等待重新调度请求，这种叫做<strong>互斥锁</strong>。</p>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p><strong>自旋锁</strong>的定义：当一个线程尝试去获取某一把锁的时候，如果这个锁此时已经被别人获取(占用)，那么此线程就无法获取到这把锁，该线程将会等待，间隔一段时间后会再次尝试获取。这种采用<strong>循环加锁 -&gt; 等待的机制</strong>被称为自旋锁(spinlock)。</p>
<p><img data-src="https://github.com/coder-Tinghao/coder-Tinghao.github.io/blob/main/images/spinlock.png?raw=true" alt="自旋锁示意图"></p>
<p>如果持有锁的线程能<strong>在短时间内释放锁资源</strong>，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞状态，它们只需要等一等(自旋)，等到持有锁的线程释放锁之后即可获取，这样就避免了用户进程和内核切换的消耗。</p>
<p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！</p>
<p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cpu 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁。</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><pre><code>public class SpinLockTest &#123;

    private AtomicBoolean available = new AtomicBoolean(false);

    public void lock()&#123;

        // 循环检测尝试获取锁
        while (!tryLock())&#123;
            // doSomething...
        &#125;

    &#125;

    public boolean tryLock()&#123;
        // 尝试获取锁，成功返回true，失败返回false
        return available.compareAndSet(false,true);
    &#125;

    public void unLock()&#123;
        if(!available.compareAndSet(true,false))&#123;
            throw new RuntimeException(&quot;释放锁失败&quot;);
        &#125;
    &#125;

&#125;
</code></pre>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p><strong>无法保证多线程竞争的公平性</strong></p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>经典原子操作——atomic operation</title>
    <url>/2023/06/10/%E7%BB%8F%E5%85%B8%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E2%80%94%E2%80%94atomic-operation/</url>
    <content><![CDATA[<h2 id="read-modify-write（RMW）"><a href="#read-modify-write（RMW）" class="headerlink" title="read-modify-write（RMW）"></a>read-modify-write（RMW）</h2><p><strong>读-修改-写（read-modify-write）</strong> 是计算机科学中的一个原子操作（atomic operation，操作过程是<strong>读一个内存位置（或IO端口），修改其值，再写回原位置</strong>。</p>
<p><strong>“read-modify-write”（RMW）原子操作指的是一种能够在单个操作中读取、修改和写入某个内存地址的操作。</strong> 这种操作通常是在多线程编程和并发编程中使用，用于确保对共享内存的并发访问不会导致竞争条件（race condition）</p>
<p>在一个RMW原子操作中，操作系统保证该操作的执行不会被其他线程中断，也就是说，在操作开始执行到结束期间，该内存地址上的任何其他操作都将被暂停。这意味着，RMW原子操作是一种不可分割的操作，不会发生其他线程对该内存地址进行操作的情况。</p>
<p>RMW原子操作通常<strong>由硬件支持</strong></p>
<p><strong>在多线程编程中，RMW原子操作通常用于实现线程间同步、加锁、计数器等功能</strong>。例如，在一个高并发的Web服务器中，可以使用RMW原子操作来保证多个线程同时访问同一个计数器变量时的正确性，避免计数器值出现不一致的情况。</p>
<h2 id="test-and-set"><a href="#test-and-set" class="headerlink" title="test and set"></a>test and set</h2><p>在计算机科学中，<strong>检查并设置（test-and-set-lock，TSL）</strong> 是一种不可中断的原子运算。TSL<strong>对某个存储器位置写入1（set）并返回其旧值</strong>。</p>
<p>在多个进程可同时访问存储器同个地址时，如果一个程序正在执行TSL，其他程序在它执行完成前不能执行TSL。</p>
<p>TAS特点是<strong>自旋</strong>，也就是循环，每次尝试去设置值，如果设置成功则会返回，如果没有返回就会一直自旋，知道设置成功值。此时进入临界区，执行完临界区数据，再设置bool变量为false。从而让其他线程拿到锁</p>
<pre><code>function Lock(boolean *lock) &#123; 
while (test_and_set(lock) == 1); 
&#125;
</code></pre>
<h2 id="fetch-and-add"><a href="#fetch-and-add" class="headerlink" title="fetch-and-add"></a>fetch-and-add</h2><p>fetch-and-add是CPU指令（FAA），对内存位置执行增加一个数量的原子操作。具体内容为：</p>
<pre><code>令x 变为x + a，其中x是个内存位置，a是个值
</code></pre>
<p>FAA可用于实现互斥锁、信号量</p>
<h2 id="compare-and-swap"><a href="#compare-and-swap" class="headerlink" title="compare-and-swap"></a>compare-and-swap</h2><p>比较并交换(compare and swap, CAS)，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值</p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>单调前缀一致性——monotonic prefix consistency</title>
    <url>/2023/06/11/%E5%8D%95%E8%B0%83%E5%89%8D%E7%BC%80%E4%B8%80%E8%87%B4%E6%80%A7%E2%80%94%E2%80%94monotonic-prefix-consistency/</url>
    <content><![CDATA[<p><a href="https://thiscute.world/posts/consistency-and-consensus-algorithm/">参考链接</a></p>
<h2 id="单调前缀一致性——monotonic-prefix-consistency"><a href="#单调前缀一致性——monotonic-prefix-consistency" class="headerlink" title="单调前缀一致性——monotonic prefix consistency"></a>单调前缀一致性——monotonic prefix consistency</h2><p>在读论文C5:cloned并发控制协议论文时遇到monotonic prefix consistency，故记录在此</p>
<p><strong>前缀一致性 Consistent Prefix</strong>：副本之间的同步过程中，会存在一些副本接收数据的顺序并不一致。「前缀一致性」是说所有用户读到的数据顺序的前缀永远是一致的。</p>
<p>「前缀」是指程序在执行写操作时，需要显式声明其「前缀」事件，这样每个事件就都存在一个由其他写事件排列而成的前缀。比如当前有写事件排列「A B C D」，那所有用户读到的数据都拥有同样的写事件前缀，比如「A」、「A B」、「A B C」、「A B C D」，但不可能出现「A C」或者「C A」等结果。</p>
<p>它解决的是<strong>分片分布式数据库的一致性问题</strong>：A B C 因为地域区别读写的是不同的副本，B 在抖音评论区问了个问题，然后 A 作出了回答。但是问题跟回答两个数据如果处于不同的分片，副本同步时这两个数据的顺序是无法保证的，C 可能会先读到回答信息，之后才刷新出 B 的提问，历史事件的顺序就乱了。<br>实现方式：需要程序主动为<strong>消息之间添加显式的依赖关系</strong>，再据此控制其读取顺序，实现比较复杂。<br>存在的问题：只有被显式定义了因果关系的事件，它们之间的顺序才能被保证。</p>
<p>问题与答案之间是有因果关系的，但这种关系在复制的过程中被忽略了，于是出现了异常。<br>保持这种因果关系的一致性，被称为前缀读或前缀一致性</p>
<p><strong>前缀一致性：在每个会话内保证了单调读，会话之间不保证</strong></p>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>c++学习笔记——9.15</title>
    <url>/2023/09/15/c-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%949-15/</url>
    <content><![CDATA[<h3 id="缓冲区（buffer）"><a href="#缓冲区（buffer）" class="headerlink" title="缓冲区（buffer）"></a>缓冲区（buffer）</h3><p>一个存储区域，用于保存数据，IO设施通常将输入输出数据保存在一个缓冲区中，可以显式刷新缓冲区</p>
<h3 id="iostream对象"><a href="#iostream对象" class="headerlink" title="iostream对象"></a>iostream对象</h3><p><strong>cerr</strong>  ostream对象，标准错误流，默认不缓冲，用于输出错误信息或其他不属于程序正常逻辑的输出内容</p>
<p><strong>clog</strong> ostream对象，标准错误流，有缓冲，用于报告程序执行信息</p>
<h3 id="endl与’-n’区别"><a href="#endl与’-n’区别" class="headerlink" title="endl与’\n’区别"></a>endl与’\n’区别</h3><p>endl相当于 ‘\n’+flush()</p>
<h3 id="类型选择"><a href="#类型选择" class="headerlink" title="类型选择"></a>类型选择</h3><p>1 明确数值不可能为负时，选无符号<br>2 选int做整数运算，超过int用long long<br>3 选double做浮点数运算</p>
<h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><p>对象是具有某种数据类型的内存空间</p>
<h3 id="分离式编译"><a href="#分离式编译" class="headerlink" title="分离式编译"></a>分离式编译</h3><ol>
<li>每个源文件（.cpp .cc等）都是一个<strong>独立的编译单元</strong>，都会被编译一遍，并生成中间文件。在 main.cpp 里，include用来【编译】时找函数声明，中间文件用来【链接】时找函数原型。</li>
<li>include简单的说就是复制粘贴而已，每个正常的头文件都会预防重复包含，如使用 #pramga once，#ifndef 等。</li>
</ol>
<p><strong>声明与定义</strong><br>c++将声明和定义区分开</p>
<p>声明 (declaration)使得名字为程序所知，一个文件如果想使用别处定义的名字则必须包含对那个名字的声明</p>
<p>定义(definition)负责<strong>创建</strong>与名字关联的实体</p>
<p>如果想声明一个变量而非定义它，就在变量名前添加关键字 extern，而且不要显式地初始化变量</p>
<pre><code>extern int i  //声明i，非定义i
int j  // 声明并定义j
</code></pre>
<p>另外，任何包含了显式初始化的声明即成为定义，如下：<br>    extern double pi &#x3D; 3.1416  &#x2F;&#x2F; 定义</p>
<h3 id="初始化建议"><a href="#初始化建议" class="headerlink" title="初始化建议"></a>初始化建议</h3><p>初始化每一个内置类型的变量</p>
<h3 id="列表初始化"><a href="#列表初始化" class="headerlink" title="列表初始化"></a>列表初始化</h3>]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>c++学习笔记——9.17</title>
    <url>/2023/09/17/c-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%949-17/</url>
    <content><![CDATA[<h3 id="静态类型"><a href="#静态类型" class="headerlink" title="静态类型"></a>静态类型</h3><p>c++ 静态类型语言，在编译阶段检查类型</p>
<h3 id="赋值和指针"><a href="#赋值和指针" class="headerlink" title="赋值和指针"></a>赋值和指针</h3><p><strong>赋值永远改变的是等号左侧的对象</strong></p>
<h3 id="const引用"><a href="#const引用" class="headerlink" title="const引用"></a>const引用</h3><p>引用类型必须与其所引用对象的类型一致<br>        const int ci &#x3D; 1024;<br>        const int &amp;r1 &#x3D; ci;</p>
<p>常量引用：常量引用是对const的引用</p>
<p>对const的引用可能引用一个非const对象：<br>常量引用，即对引用加const，只是<strong>限定了引用可参与的操作</strong>，对于引用的对象本身没有限定<br>        int i &#x3D; 42;<br>        const int &amp;r1 &#x3D; i;<br>        r1 &#x3D; 0;  &#x2F;&#x2F; <strong>非法，常量引用不能修改</strong></p>
<h4 id="指针和const"><a href="#指针和const" class="headerlink" title="指针和const"></a>指针和const</h4><p>指向常量的指针和常量引用类似，<br>        const int i &#x3D; 42;<br>        const int *i &#x3D; &amp;i;<br>        *i &#x3D; 0;  &#x2F;&#x2F; <strong>非法，不能修改值</strong></p>
<h4 id="const指针"><a href="#const指针" class="headerlink" title="const指针"></a>const指针</h4><pre><code>    const int i = 42;
    const int *const r1 = &amp;i;
</code></pre>
<p>*<strong>const为const指针，不变的是指针本身的值，而指向的值</strong></p>
<h3 id="顶层const和底层const"><a href="#顶层const和底层const" class="headerlink" title="顶层const和底层const"></a>顶层const和底层const</h3><p>顶层 const 表示指针本身是个常量；<br>底层 const 表示指针所指的对象是一个常量<br>or<br>被修饰的变量本身无法改变的 const 是顶层 const；<br>通过指针或引用等间接途径来限制目标内容不可变的 const 是底层 const</p>
<h3 id="constexpr"><a href="#constexpr" class="headerlink" title="constexpr"></a>constexpr</h3><p>常量表达式：值不会改变，编译过程就能得到计算结果的表达式</p>
<p>C++11:constexpr，如果认定变量是常量表达式，就声明为constexpr</p>
<h3 id="别名"><a href="#别名" class="headerlink" title="别名"></a>别名</h3><p>别名声明<br>    using SI &#x3D; Sales_item;  &#x2F;&#x2F; SI是Sales_item的同义词（Sales_item是一个类型）</p>
<h3 id="预处理器概述"><a href="#预处理器概述" class="headerlink" title="预处理器概述"></a>预处理器概述</h3><p>预处理功能 #include，当预处理器看到#include标记时就会用指定的头文件内容代替#include</p>
<h3 id="decltype类型指示符"><a href="#decltype类型指示符" class="headerlink" title="decltype类型指示符"></a>decltype类型指示符</h3><p>选择并返回操作数的数据类型<br>使用情况：希望从表达式的类型推断出要定义的变量的类型，但是不想用该表达式的值初始化变量</p>
<h3 id="string-size-type类型"><a href="#string-size-type类型" class="headerlink" title="string::size_type类型"></a>string::size_type类型</h3><p>string类的配套类型，<strong>无符号类型</strong>，能足够存放下任何string对象的大小（通常等于 std::size_t）<br>访问string对象的下标也是size_type类型，<strong>使用该类型访问string中的字符可以保证安全（无符号）</strong></p>
<p>注：size()函数无符号，要避免和int类型混用带来的问题</p>
<h3 id="int类型和unsigned-int类型混用问题"><a href="#int类型和unsigned-int类型混用问题" class="headerlink" title="int类型和unsigned int类型混用问题"></a>int类型和unsigned int类型混用问题</h3><p>int和unsigned int类型进行混合算数运算时，运算结果为<strong>非负数时，结果不会出现异常</strong>，当运算结果为<strong>负数时就会出现异常结果，往往异常结果值会很大</strong></p>
<h3 id="字面值与string对象"><a href="#字面值与string对象" class="headerlink" title="字面值与string对象"></a>字面值与string对象</h3><p>字符串字面值和string是不同的类型<br>        string s1 &#x3D; “hello”;<br>        string s2 &#x3D; s1 + “test”;  &#x2F;&#x2F; 正确，会转化为string类型<br>        string “hello” + “test”;  &#x2F;&#x2F; 错误，两个都不是string类型</p>
]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>c++学习笔记——9.20</title>
    <url>/2023/09/20/c-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%949-20/</url>
    <content><![CDATA[<h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><p>对于c++的迭代器，<strong>只有!&#x3D;</strong> 没有&lt;</p>
<p>迭代器分为两种：<br>        vector<int>::iterator it1;  &#x2F;&#x2F; 能读写<br>        vector<int>::const_iterator it2;  &#x2F;&#x2F; 只读，不能写<br>若想得到const_iterator，有<strong>cbegin(),cend();</strong></p>
<p><strong>但凡使用迭代器的循环体，都不要向容器添加元素</strong></p>
<p><strong>std::difference_type</strong> 是C++标准库中的一种类型，通常与容器迭代器相关。它是一个有符号整数类型，用于表示两个迭代器之间的距离（差异）</p>
<p>与size_type()函数类似 <strong>目的是确保在不同平台和编译器中，容器迭代器的距离计算都能正确工作，因为不同的平台和编译器可能会有不同的整数大小，保证可移植性</strong></p>
<h3 id="size-t和size-type的区别（来自chatgpt，未完全理解）"><a href="#size-t和size-type的区别（来自chatgpt，未完全理解）" class="headerlink" title="size_t和size_type的区别（来自chatgpt，未完全理解）"></a>size_t和size_type的区别（来自chatgpt，未完全理解）</h3><p><strong>size_t：</strong> size_t是C和C++<strong>标准库</strong>中定义的一种无符号整数类型，通常用于表示对象的大小、元素数量或者数组的索引，它不是一个特定容器或类型的成员</p>
<p><strong>size_type：</strong> size_type是一些<strong>标准库容器类</strong>的成员类型，例如 std::vector、std::string、std::deque等，是<strong>容器类特定</strong>的无符号整数类型，用于表示容器的大小、元素数量或者迭代器之间的距离。</p>
<p>在使用容器的成员函数时，应该使用容器的 size_type 类型，以确保代码在容器的上下文中正常工作。例如，在使用 std::vector 时，应该使用 std::vector::size_type 来表示容器的大小。</p>
<h3 id="箭头运算符-gt"><a href="#箭头运算符-gt" class="headerlink" title="箭头运算符 -&gt;"></a>箭头运算符 -&gt;</h3><p>箭头运算符 &#x3D; 解引用 + 成员访问<br>        it-&gt;mem<br>        (*it).mem<br>上面两句意思相同</p>
<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>编译时维度已知，所以维度必须是一个<strong>常量表达式</strong></p>
<p><strong>字符数组：用字符串字面值初始化字符数组时，字符串字面值的结尾有一个空字符</strong><br>        char a[] &#x3D; “Daniel”； &#x2F;&#x2F; 自动添加表示空字符串结束的空字符，所以维度为7</p>
<p><strong>使用数组下标时，通常定义为size_t类型</strong>，是一种机器相关的<strong>无符号类型</strong><br>size_t 的大小在不同的编译器和平台上可能会有所不同，但它的目的是确保能够安全地表示当前系统上的最大对象大小<br>通常被用于与内存分配和数据结构相关的操作，以确保代码的可移植性</p>
<h3 id="数组指针"><a href="#数组指针" class="headerlink" title="数组指针"></a>数组指针</h3><p>从内向外看<br>int *ptr[10]; &#x2F;&#x2F; ptr是含有10个整型指针的数组<br>int (*ptr)[10] &#x3D; &amp;arr; &#x2F;&#x2F; ptr指向一个含有10个整数的数组</p>
]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>c++学习笔记——9.21</title>
    <url>/2023/09/21/c-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%949-21/</url>
    <content><![CDATA[<h3 id="标准库函数begin和end"><a href="#标准库函数begin和end" class="headerlink" title="标准库函数begin和end"></a>标准库函数begin和end</h3><pre><code>    int ia[] = &#123;0, 1, 2, 3&#125;;
    int *beg = begin(ia); // 指向ia首元素的指针
    int *last = end(ia); // 指向ia尾元素的下一个位置的指针
</code></pre>
<h3 id="左值和右值"><a href="#左值和右值" class="headerlink" title="左值和右值"></a>左值和右值</h3><p>当一个对象被用作右值，用的是对象的<strong>值（内容）</strong><br>当一个对象被用作左值，用的是对象的<strong>身份（在内存中的位置）</strong></p>
<h3 id="自增-自减运算符"><a href="#自增-自减运算符" class="headerlink" title="自增 自减运算符"></a>自增 自减运算符</h3><p><strong>除非必须，否则不用自增自减运算符的后置版本（i++）</strong><br>原因：后置版本会先将原始值存储下来，不必要</p>
<h3 id="const形参和实参"><a href="#const形参和实参" class="headerlink" title="const形参和实参"></a>const形参和实参</h3><p>函数中不会改变的形参定义为<strong>常量引用</strong></p>
<h3 id="含有可变形参的函数"><a href="#含有可变形参的函数" class="headerlink" title="含有可变形参的函数"></a>含有可变形参的函数</h3><p>1 如果所有实参类型相同，可用initialzer_list（标准库类型），initialzer_list是一个模版类型<br>        void error_msg(initialzer_list<string> i) {<br>            …<br>        }</p>
<p>2 如果实参类型不同，</p>
]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——9.26</title>
    <url>/2023/09/26/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%949-26/</url>
    <content><![CDATA[<h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>java字符串，String类对象<strong>不可变</strong></p>
<p>优点：编译器可以让字符串<strong>共享</strong></p>
<p>字符串字面值存放在<strong>常量池</strong>（也是在堆内存中）</p>
<pre><code>    String s1 = &quot;abc&quot;; // 通过赋值的方式初始化
    String s2 = &quot;abc&quot;;
    System.out.println(s1==s2); // 返回true，说明在常量池的同一个地方
</code></pre>
<p>若通过new初始化，则在堆内存中，不在常量池中</p>
<pre><code>    String s1 = new String(&quot;abc&quot;);
    String s2 = new String(&quot;abc&quot;);
    System.out.println(s1==s2); // 返回false，说明s2创建时，在堆内存中又新建了一个“abc”对象
</code></pre>
<p>所以，通过直接赋值的方式进行初始化还可以节省空间</p>
<h4 id="检测字符串相等"><a href="#检测字符串相等" class="headerlink" title="检测字符串相等"></a>检测字符串相等</h4><p>用.equals()方法检测</p>
<p>&#x3D;&#x3D; 运算符只能确定两个字符串是否存放在同一位置<br>只有字符串字面值会共享，+和substring得到的字符串不共享</p>
<h4 id="空串与null"><a href="#空串与null" class="headerlink" title="空串与null"></a>空串与null</h4><p>空串是一个对象，长度为0，内容为空</p>
<pre><code>    str.length() == 0;
    str.equals(&quot;&quot;);
</code></pre>
<p>null表示没有任何对象与该变量相关联</p>
<pre><code>    str === null
</code></pre>
<h4 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h4><p>StringBuilder和StringBuffer都可以理解成容器，用于<strong>支持String修改操作</strong></p>
<p><strong>StringBuilder</strong><br>如果所有字符串编辑操作都单线程执行，应当使用StringBuilder</p>
<pre><code>    StringBuilder sb = new StringBuilder();
    sb.append(str1);
    sb.append(str2);
    String ret = sb.toString();
</code></pre>
<p><strong>源码分析</strong><br>长度 .length() ：实际存了多少<br>容量 .capacity() :最多可以存多少<br>初始容量为<strong>指定字符串 +16</strong>，若初始化时为空，容量就是16；也可以指定容量</p>
<h4 id="扩容机制"><a href="#扩容机制" class="headerlink" title="扩容机制"></a>扩容机制</h4><p>若不够，先扩容为2倍+2；若还不够，扩容为字符串实际长度<br>扩容就是创建一个新容量的byte数组，把字符串内容复制进去，再返回</p>
<p><strong>StringBuffer</strong><br>与StringBuilder类似，没有StringBuilder速度快，多数情况下用Builder<br>但是，StringBuilder不是线程安全的，<strong>若要求线程安全必须用StringBuffer</strong></p>
<p><strong>原因</strong>：StringBuffer中所有方法都是synchronized修饰的，同一时间只能有一个线程访问，StringBuilder中的操作有非原子操作。但是实际情况中，String的构建几乎不涉及多线程场景</p>
<p><strong>StringJoiner</strong><br>StringJoiner基于StringBuilder构建的适用于<strong>字符拼接</strong>的场景</p>
<pre><code>    StringJoiner sj = new StringJoiner(&quot;,&quot;); // 指定分隔符
    sj.add(&quot;张三&quot;).add(&quot;李四&quot;).add(&quot;王五&quot;); // 添加元素
    String result = sj.toString(); // 转换为字符串
    System.out.println(result); // 张三,李四,王五
</code></pre>
<h3 id="字符串拼接底层原理"><a href="#字符串拼接底层原理" class="headerlink" title="字符串拼接底层原理"></a>字符串拼接底层原理</h3><p>如果没有变量参与，编译时会进行优化，<strong>编译时拼接起来，会复用常量池中的字符串</strong></p>
<pre><code>    String s1 = &quot;abc&quot;;
    String s2 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;
    System.out.println(s1==s2); // 返回true，
</code></pre>
<p>如果有变量参与，每一行拼接都会在内存中创建新字符串对象，浪费内存</p>
<h4 id="StringBuilder优化原理"><a href="#StringBuilder优化原理" class="headerlink" title="StringBuilder优化原理"></a>StringBuilder优化原理</h4><p>创建一次StringBuilder对象，所有要拼接的都往这一个对象放，节约内存</p>
<h3 id="块作用域"><a href="#块作用域" class="headerlink" title="块作用域"></a>块作用域</h3><p>java不允许在嵌套的块中重定义变量<br>java不能实现运算符重载</p>
<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>快速打印数组</p>
<pre><code>    int[] a = new int[100];
    System.out.println(Arrays.toString(a));
</code></pre>
<p>快速打印二维数组</p>
<pre><code>    int[] a = new int[100][100];
    System.out.println(Arrays.deeptoString(a));
</code></pre>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——9.29</title>
    <url>/2023/09/29/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%949-29/</url>
    <content><![CDATA[<h3 id="java堆"><a href="#java堆" class="headerlink" title="java堆"></a>java堆</h3><p>java new出来的对象都<strong>大多</strong>是在堆中构造的，不绝对</p>
<h3 id="java-var关键字"><a href="#java-var关键字" class="headerlink" title="java var关键字"></a>java var关键字</h3><p>var关键字用于<strong>局部变量的类型推导</strong>，参数和字段的类型必须声明</p>
<h3 id="java类"><a href="#java类" class="headerlink" title="java类"></a>java类</h3><p>只访问对象而不修改对象——<strong>访问器方法</strong></p>
<pre><code>getXXX() &#123;
    
&#125;
</code></pre>
<p>能修改的——<strong>修改器方法</strong></p>
<pre><code>setXXX() &#123;

&#125;
</code></pre>
<h3 id="null引用"><a href="#null引用" class="headerlink" title="null引用"></a>null引用</h3><p>没有任何引用对象</p>
<pre><code>// 对象引用参数为null时，转化为非null值
public Emmployee(String name, int age) &#123;
    name = Objects.requireNonNullElse(n, &quot;unknown&quot;);
&#125;

// 对象引用参数为null时，产生异常
// 但可以准确定位，会提供问题描述
public Emmployee(String name, int age) &#123;
    name = Objects.requireNonNull(n, &quot;name cannot be null&quot;);
&#125;
</code></pre>
<h3 id="方法参数（java核心技术P122）"><a href="#方法参数（java核心技术P122）" class="headerlink" title="方法参数（java核心技术P122）"></a>方法参数（java核心技术P122）</h3><p>参数类型：基本数据类型，对象引用</p>
<p>java中总是采用<strong>按值传递</strong>，方法不可能修改基本数据类型的参数</p>
<p>传入一个<strong>对象参数</strong>就可以实现修改</p>
<p>原因：Java中实际上对象引用也是按值传递的<br>参数传一个对象引用，因为是值传递，可以获得一个对象引用的副本（个人理解：就是传入这个对象地址值的副本，和远对象引用指向同一个对象）那么这个对象引用的副本就可以操作这个对象修改所引用对象的状态</p>
<h3 id="java记录"><a href="#java记录" class="headerlink" title="java记录"></a>java记录</h3><p>特殊类，状态不可变，公共可读</p>
<pre><code>record Point(double x, double y) &#123; &#125;
var p = new Point(3, 4);
sout(p.x() + p.y());
</code></pre>
<p>访问器方法名为变量名</p>
<h3 id="java静态绑定和动态绑定"><a href="#java静态绑定和动态绑定" class="headerlink" title="java静态绑定和动态绑定"></a>java静态绑定和动态绑定</h3><p>静态绑定发生在编译时期，动态绑定发生在运行时</p>
<p>使用private或static或final修饰的变量或者方法，编译器可以准确的知道可以调用哪个方法，使用静态绑定<br>可以被子类重写的方法则会根据运行时的对象进行动态绑定</p>
<p>动态绑定过程：<br>jvm会为每个类生成一个<strong>方法表</strong>，方便在调用方法时查找该用哪个方法</p>
<h3 id="Object类"><a href="#Object类" class="headerlink" title="Object类"></a>Object类</h3><p><strong>toString方法</strong><br>返回一个表示对象的值的字符串<br>用法：例如下面的代码，常用于自定义toString方法，来<strong>方便获取和打印对象状态</strong>的有用信息</p>
<pre><code>public String toString() &#123;
    return getClass().getName()
    + &quot;name=&quot; + name;
&#125;
</code></pre>
<h3 id="包装器"><a href="#包装器" class="headerlink" title="包装器"></a>包装器</h3><p>如：Integer对应int<br><strong>包装器类是不可变的，不允许更改里面的值</strong>，且是final的</p>
<h3 id="密封类sealed"><a href="#密封类sealed" class="headerlink" title="密封类sealed"></a>密封类sealed</h3><p>可以控制哪些类可以继承他</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——10.9</title>
    <url>/2023/10/05/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%9410-9/</url>
    <content><![CDATA[<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p><strong>为什么不用抽象类表示通用属性？</strong><br>java中没有多重继承，每个类只能扩展一个类，那比如一个类想扩展多个抽象功能，就做不到了<br>接口提供多重继承，每个类可以实现任意多个接口</p>
<h3 id="回调"><a href="#回调" class="headerlink" title="回调"></a>回调</h3><p>回调函数（callback function）所指的是一个函数作为参数传递到另一个函数，并且它将在某些“事件”（条件判定、函数调用、按钮点击事件或者是计时器计时等）触发后被调用执行，以完成我们指定的任务</p>
<h3 id="克隆与拷贝"><a href="#克隆与拷贝" class="headerlink" title="克隆与拷贝"></a>克隆与拷贝</h3><p>拷贝：原变量和副本都是同一个对象的引用（引用拷贝）<br>克隆：是copy一个新对象，初始状态和原来相同，需要使用<strong>clone()方法</strong></p>
<p>所有数组类型都有一个公共的clone方法，且不受保护</p>
<pre><code>int[] a = &#123;1,2,3,4,5&#125;;
int[] b = a.clone()
b[4] = 2; // 不会改变a数组中的值
</code></pre>
<h4 id="深拷贝和浅拷贝-（java核心技术P248）"><a href="#深拷贝和浅拷贝-（java核心技术P248）" class="headerlink" title="深拷贝和浅拷贝 （java核心技术P248）"></a>深拷贝和浅拷贝 （java核心技术P248）</h4><p>暂时浅浅理解</p>
<p>浅拷贝：克隆的默认操作，没有克隆对象中引用的其他对象<br>深拷贝：深拷贝把要复制的对象<strong>所引用的对象</strong>都复制了一遍<br>这两种拷贝都叫<strong>对象拷贝</strong></p>
<h3 id="lambda表达式及函数式接口"><a href="#lambda表达式及函数式接口" class="headerlink" title="lambda表达式及函数式接口"></a>lambda表达式及函数式接口</h3><p><strong>函数式接口就是只有一个抽象方法的接口</strong>，比如典型的Comparator接口就是只有一个方法的接口（就一个函数，像个函数似的但是是接口，就叫函数式接口，没毛病）<br>对于Arrays.sort(xx, xx)  这个sort方法会接收实现了Comparator<String>某个类的对象，在对象上调用compare方法</p>
<p>设计函数式接口时，可以加上@<strong>FunctionalInterface注解</strong>，用于检查是否只有一个抽象方法和javadoc页可以指出这是一个函数式接口</p>
<pre><code>@FunctionalInterface
interface MathOperation &#123;
    int operate(int a, int b);
&#125;

MathOperation addition = (a, b) -&gt; a + b; // 使用Lambda表达式来创建函数式接口的实例
int result = addition.operate(5, 3); // 调用MathOperation接口的operate方法
System.out.println(result); // 输出8
</code></pre>
<p>lambda表达式可以转换为接口（只转换为函数式接口）<br><strong>把lambda表达式看作一个函数</strong>，而不是对象，且可以传递到函数式接口<br>lambda表达式可以捕获外围作用域的<strong>事实最终变量（初始化后就不再被赋新值）</strong></p>
<p><strong>和c++的区别就是</strong>：c++传的是个函数指针，java传的是个实现了这个接口的类的对象，从这个对象调这个函数</p>
<h3 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h3><p>方法引用是用来简化Lambda表达式的一种方式，它可以将已存在的方法引用为Lambda表达式的实现，方法引用适用于Lambda表达式的签名与被引用方法的签名兼容的情况</p>
<p>包括静态方法、实例方法、构造方法<br>（具体见《java核心技术》P258）</p>
<h3 id="java代理"><a href="#java代理" class="headerlink" title="java代理"></a>java代理</h3><p>涉及反射，后续看完反射回头看</p>
<h3 id="java容器"><a href="#java容器" class="headerlink" title="java容器"></a>java容器</h3><h4 id="Iterator接口"><a href="#Iterator接口" class="headerlink" title="Iterator接口"></a>Iterator接口</h4><p>认为Java迭代器位于两个元素之间，调用next，迭代器会越过下一个元素，并返回越过的这个元素的引用<br>迭代器必须顺序访问集合</p>
<p><strong>ListIterator接口</strong>有两个方法可以反向遍历链表</p>
<pre><code>E previous()
boolean hasPrevious()
</code></pre>
<p>与next方法一样，previous方法会返回越过的对象</p>
<h4 id="动态数组"><a href="#动态数组" class="headerlink" title="动态数组"></a>动态数组</h4><p>Vector的所有方法是<strong>同步的</strong>，线程安全<br>ArrayList方法不是同步的</p>
<h4 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h4><p>Java中，散列表的实现为链表数组，每个列表为桶；当桶满时，链表会变为平衡二叉树</p>
<h4 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a>TreeSet</h4><p>与散列集很像，是一个有序集合，遍历时自动按照排序后顺序出现（排序目前用的是红黑树）；且HashSet稍快一些<br>要使用这个TreeSet，元素必须实现Comparable接口或者提供Comparator</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——10.12</title>
    <url>/2023/10/12/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%9410-12/</url>
    <content><![CDATA[<h3 id="断言"><a href="#断言" class="headerlink" title="断言"></a>断言</h3><pre><code>assert condition;
assert condition: expression;
</code></pre>
<p>expression表达式部分为了<strong>生成一个消息字符串</strong></p>
<h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><h4 id="类型擦除"><a href="#类型擦除" class="headerlink" title="类型擦除"></a>类型擦除</h4><p><strong>Java虚拟机没有泛型类型对象，所有对象都属于普通类</strong><br>对于一个泛型类型，都会自动提供一个<strong>原始类型</strong><br>对于无限定的类型变量，会被替换为Object；对于有限定的，用第一个限定来替换类型变量<br>例如：List<T> 在运行时被视为List<Object></p>
<h4 id="Java桥方法"><a href="#Java桥方法" class="headerlink" title="Java桥方法"></a>Java桥方法</h4><p>虚拟机合成桥方法以保持多态<br>暂时没看懂。。。</p>
<p>泛型类型继承机制<br>考虑一个类和一个子类Employee和Manager，<strong>Pair<Manager>不是Pair<Employee>的子类型</strong></p>
<h4 id="通配符类型"><a href="#通配符类型" class="headerlink" title="通配符类型"></a>通配符类型</h4><p>没看懂</p>
<h4 id="反射和泛型"><a href="#反射和泛型" class="headerlink" title="反射和泛型"></a>反射和泛型</h4><p>没看懂</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——11.20</title>
    <url>/2023/11/20/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%9411-20/</url>
    <content><![CDATA[<h2 id="Java集合"><a href="#Java集合" class="headerlink" title="Java集合"></a>Java集合</h2><p>Java集合由两大接口派生：<strong>Collection接口、Map接口</strong><br>Collection接口下面，有三个主要的子接口：<strong>List、Set 和 Queue</strong></p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>ArrayList，底层用**Object[]**存储，线程不安全，适用于频繁查找，支持快速随机访问（实现了RandomAccess接口）</p>
<p>Vector，底层用**Object[]**存储，线程安全</p>
<p>LinkedList底层用<strong>双向链表</strong>，一般是不会使用到LinkedList，需要用到 LinkedList的场景几乎都可以使用 ArrayList 来代替，并且，性能通常会更好</p>
<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>HashSet，底层基于HashMap实现，保存元素，用于不需要保证元素插入和取出顺序的场景</p>
<p>LinkedHashSet，通过 LinkedHashMap来实现，链表和哈希表，<strong>元素的插入和取出顺序满足 FIFO</strong></p>
<p>TreeSet，红黑树，支持对元素自定义排序规则的场景</p>
<h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>PriorityQueue，Object[]数组来实现小顶堆</p>
<p>DelayQueue，只有到了其指定的延迟时间，才能够从队列中出队</p>
<p>ArrayDeque，可扩容动态双向数组</p>
<h3 id="Deque"><a href="#Deque" class="headerlink" title="Deque"></a>Deque</h3><p>双端队列，扩展了Queue接口</p>
<h3 id="ArrayDeque-与-LinkedList-的区别"><a href="#ArrayDeque-与-LinkedList-的区别" class="headerlink" title="ArrayDeque 与 LinkedList 的区别"></a>ArrayDeque 与 LinkedList 的区别</h3><p>ArrayDeque 是基于<strong>可变长的数组和双指针</strong>来实现，而 LinkedList 则通过<strong>链表</strong>实现</p>
<h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><p>HashMap，<strong>数组+链表</strong>，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间</p>
<p>LinkedHashMap，</p>
<p>Hashtable，数组+链表，比HashMap多了个<strong>线程安全</strong></p>
<p>TreeMap，红黑树</p>
<p>ConcurrentHashMap，<strong>并发环境</strong>下，推荐使用</p>
<h3 id="Java集合fail-last机制"><a href="#Java集合fail-last机制" class="headerlink" title="Java集合fail-last机制"></a>Java集合fail-last机制</h3><p>fail-fast 机制是java集合(Collection)中的一种错误机制。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件</p>
<p>迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在 被遍历期间如果内容发生变化，就会改变modCount 的值。每当迭代器使用hashNext()&#x2F;next()遍历下一 个元素之前，都会检测 modCount变量是否为expectedmodCount值，是的话就返回遍历;否则抛出 异常，终止遍历</p>
<p><strong>不要在 foreach 循环里进行元素的 remove&#x2F;add 操作</strong>，remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。通过反编译你会发现 foreach 语法底层其实还是依赖 Iterator 。不过， <strong>remove&#x2F;add 操作直接调用的是集合自己的方法，而不是 Iterator 的 remove&#x2F;add方法，迭代器就会发现自己有元素被remove&#x2F;add，就抛异常了</strong></p>
<p>除了使用Iterator进行遍历操作外：<br>使用 fail-safe 的集合类，<br><strong>java.util包下面的所有的集合类都是 fail-fast 的，而java.util.concurrent包下面的所有的类都是 fail-safe</strong></p>
<h3 id="集合只读"><a href="#集合只读" class="headerlink" title="集合只读"></a>集合只读</h3><p>Collections. unmodifiableCollection(Collection c)方法来创建一个 只读集合，改变集合 的任何操作都会抛出 Java. lang. UnsupportedOperationException 异常</p>
<h3 id="迭代器Iterator"><a href="#迭代器Iterator" class="headerlink" title="迭代器Iterator"></a>迭代器Iterator</h3><pre><code>List&lt;String&gt; list = new ArrayList
Iterator&lt;String&gt; it = list. iterator
while(it. hasNext())&#123;
    String obj = it. next();
    System. out. println(obj);
&#125;
</code></pre>
<p>在当前遍历 的集合元素被更改的时候，就会抛出 ConcurrentModificationException 异常，如果要删除元素就用iterator.remove()</p>
<h3 id="Iterator与ListIterator"><a href="#Iterator与ListIterator" class="headerlink" title="Iterator与ListIterator"></a>Iterator与ListIterator</h3><p>Iterator 可以遍历 Set 和 List 集合，而 ListIterator 只能遍历 List<br>Iterator 只能<strong>单向遍历</strong>，而 ListIterator 可以<strong>双向遍历(向前&#x2F;后遍历)</strong></p>
<h3 id="List遍历的最佳实践"><a href="#List遍历的最佳实践" class="headerlink" title="List遍历的最佳实践"></a>List遍历的最佳实践</h3><p><strong>支持 Random Access 的列表可用 for 循环遍历，否则建议 用 Iterator 或 foreach 遍历</strong></p>
<h3 id="Comparable-和-Comparator-的区别"><a href="#Comparable-和-Comparator-的区别" class="headerlink" title="Comparable 和 Comparator 的区别"></a>Comparable 和 Comparator 的区别</h3><p>Comparable 接口实际上是出自java.lang包，它有一个 c**ompareTo(Object obj)**方法用来排序</p>
<p>Comparator接口实际上是出自 java.util 包它有一个c**ompare(Object obj1, Object obj2)**方法用来排序</p>
<h3 id="集合去重"><a href="#集合去重" class="headerlink" title="集合去重"></a>集合去重</h3><p><strong>可以利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作</strong>，避免使用 List 的 contains() 进行遍历去重或者判断包含操作</p>
<p>HashSet 的 contains() 方法底部依赖的 HashMap 的 containsKey() 方法，时间复杂度接近于<strong>O（1）</strong></p>
<p>ArrayList 的 contains() 方法是通过遍历所有元素的方法来做的，时间复杂度接近是 <strong>O(n)</strong></p>
<h3 id="Arrays-asList"><a href="#Arrays-asList" class="headerlink" title="Arrays.asList()"></a>Arrays.asList()</h3><p>当传入一个原生数据类型数组时，Arrays.asList() 的真正得到的参数就不是数组中的元素，而是数组对象本身！此时 List 的唯一元素就是这个数组</p>
<p>Arrays.asList()方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类</p>
<p>List.of()方法适用于需要创建一组固定的、不可变的元素列表的场景</p>
<h3 id="字符流与字节流"><a href="#字符流与字节流" class="headerlink" title="字符流与字节流"></a>字符流与字节流</h3><p>处理纯文本数据，优先考虑使用字符流，除此之外都使用字节流</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——11.21</title>
    <url>/2023/11/21/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%9411-21/</url>
    <content><![CDATA[<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p><strong>b树索引</strong><br><strong>B树可以在内部节点同时存储键和值</strong>，频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率，键和值存放在内部节点和叶子节点</p>
<p><strong>b+树索引</strong><br><strong>B+树的内部节点只存放键，不存放值</strong>，叶子节点有一条链相连，天然<strong>支持范围查询</strong></p>
<p>当需要进行一次全数据遍历的时候，B+树只需 要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可</p>
<p><strong>hash索引</strong>，不支持范围查，查询效率不稳定</p>
<p>较频繁作为<strong>查询条件</strong>的字段才去创建索引，<strong>更新频繁字段</strong>不适合创建索引</p>
<h3 id="为什么用B-树而不是B树"><a href="#为什么用B-树而不是B树" class="headerlink" title="为什么用B+树而不是B树"></a>为什么用B+树而不是B树</h3><p><strong>B树</strong><br>随机检索<br>元素遍历（范围查询）效率低下</p>
<p><strong>B+树</strong><br>同时支持随机检索和顺序检索<br>内部结点不存值，比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，<strong>IO读写次数</strong>也就降低了</p>
<h3 id="聚簇索引和非聚簇索引"><a href="#聚簇索引和非聚簇索引" class="headerlink" title="聚簇索引和非聚簇索引"></a>聚簇索引和非聚簇索引</h3><p>聚簇索引：数据存储与索引放到了一块，找到索引也就找到了数据；叶子节点存储的是行数据，因此通过聚簇索引可以直接找到真正的行数据</p>
<p>非聚簇索引：数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，通过 key_buffer把索引先<strong>缓存到内存中</strong>；叶子节点存储的是主键信息，所以使用非聚簇索引还需要<strong>回表查询</strong></p>
<p>聚簇索引一般是主键索引，一个表中也只能有一个，而非聚簇索引则没有数量上的限制</p>
<h3 id="一定需要回表查询吗？"><a href="#一定需要回表查询吗？" class="headerlink" title="一定需要回表查询吗？"></a>一定需要回表查询吗？</h3><p>不一定，取决于<strong>查询语句所要求的字段是否全部命中了索引</strong>，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age &lt; 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询</p>
<h3 id="MySQL隔离级别"><a href="#MySQL隔离级别" class="headerlink" title="MySQL隔离级别"></a>MySQL隔离级别</h3><p>因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读 取提交内容):，但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ(可重读)并不会有 任何性能损失<br><strong>InnoDB 存储引擎在 分布式事务 的情况下一般会用到SERIALIZABLE(可串行化)隔离级别</strong></p>
<h3 id="隔离级别和锁"><a href="#隔离级别和锁" class="headerlink" title="隔离级别和锁"></a>隔离级别和锁</h3><p>在Read Uncommitted级别下，<strong>读取数据不需要加共享锁</strong>，这样就不会跟被修<br>改的数据上的排他锁冲突</p>
<p>在Read Committed级别下，<strong>读操作需要加共享锁</strong>，但是在语句<strong>执行完以后释放共享锁</strong></p>
<p>在Repeatable Read级别下，<strong>读操作需要加共享锁，但是在事务提交之前并不释放共享锁</strong>，也就是必须等待事务执行完毕以后才释放共享锁</p>
<p>SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成</p>
<h3 id="锁粒度"><a href="#锁粒度" class="headerlink" title="锁粒度"></a>锁粒度</h3><p>行级锁、表级锁、页级锁；具体还分<strong>共享锁和排他锁</strong> 还有<strong>意向锁（预先通知）</strong><br>InnoDB支持行级锁和表级锁，<strong>默认为行级锁</strong></p>
<p><strong>行级锁</strong> 开销大，加锁慢;会出现死锁;锁定粒度最小，发生锁冲突的概率最低；并发度最高</p>
<p><strong>表级锁</strong> 开销小，加锁快;不会出现死锁（也有可能吧）;锁定粒度大，发出锁冲突的概率最高</p>
<p><strong>页级锁</strong> 中间</p>
<h3 id="MySQL行锁"><a href="#MySQL行锁" class="headerlink" title="MySQL行锁"></a>MySQL行锁</h3><p>InnoDB是基于<strong>索引</strong>来完成行锁<br>例: select * from tab_with_index where id &#x3D; 1 for update;<br>for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id不是索引键那么InnoDB将 完成表锁，并发将无从谈起</p>
<h3 id="InnoDB存储引擎的锁"><a href="#InnoDB存储引擎的锁" class="headerlink" title="InnoDB存储引擎的锁"></a>InnoDB存储引擎的锁</h3><p>Record lock:单个行记录上的锁<br>Gap lock:间隙锁，锁定一个范围，不包括记录本身<br>Next-key lock:record+gap 锁定一个范围，包含记录本身</p>
<p>Gap Lock 的作用是为了<strong>阻止多个事务将记录插入到同一个范围内</strong>，因为这会导致幻读问题（phantom Problem）的产生</p>
<h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><p>虚拟表</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——11.22</title>
    <url>/2023/11/22/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%9411-22/</url>
    <content><![CDATA[<h3 id="Innodb事务"><a href="#Innodb事务" class="headerlink" title="Innodb事务"></a>Innodb事务</h3><p><strong>redo log</strong><br>redo log就是保存执行的SQL语句到一个指定的Log文件，当Mysql执行recovery时重新执行redo log记录的SQL操作即可,当客户端执行每条SQL(更新语句)时，redo log会被首先写入log buffer;当客户端执行COMMIT命令时，log buffer中的内容会被视情况刷新到磁盘</p>
<p><strong>undo log</strong><br>undo log是为回滚而用，就是copy事务前的数据库内容(行)到undo buffer，在适合的时间把undo buffer中的内容刷新到磁盘</p>
<h3 id="Java内存泄漏"><a href="#Java内存泄漏" class="headerlink" title="Java内存泄漏"></a>Java内存泄漏</h3><p>未引用对象将会被垃圾回收器回收，而引用对象却不会。<br>未引用对象很显然是无用的对象，有一些无用对象也有可能是引用对象，<strong>这部分对象正是内存泄露的来源</strong></p>
<p><strong>为什么会发生？</strong><br>对象A引用对象B，A的生命周期(t1- t4)比B的生命周期(t2-t3)要长，当B在程序中不再被使用的时候，A仍然引用着B。在这种情况下， 垃圾回收器是不会回收B对象的，这就可能造成了内存不足问题</p>
<p>因为A可能不止引用着B对象，还可能 引用其它生命周期比A短的对象，这就造成了大量无用对象不能被回收，且占据了昂贵的内存资源。</p>
<p>同样的，B对象也可能引用着一大堆对象，这些被B对象引用着的对象也不能被垃圾回收器回收，所有的 这些无用对象消耗了大量内存资源。</p>
<p><strong>如何阻止？</strong><br>使用集合、大对象、文件等时，及时赋值为null或关闭</p>
<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p><strong>工作原理</strong><br>刚开始都是在创建新的线程，达到<strong>核心线程数量5个后，新的任务进来后不再创建新的线程，而是将任务加入工作队列</strong>，任务队列到达上线5个后，新的任务又会创建新的普通线程，直到达到线程池最大的线 程数量10个，后面的任务则根据配置的饱和策略来处理<br><img data-src="/image.png" alt="Alt text"><br><strong>优点</strong><br>1、线程是稀缺资源，使用线程池可以减少创建和销毁线程的次数，每个工作线程都可以重复使用</p>
<p>2、可以根据系统的承受能力，调整线程池中工作线程的数量，防止因为消耗过多内存导致服务器崩溃</p>
<p>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。<br>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。<br>提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。</p>
<h3 id="Executor框架两级调度（Java岗面试核心MCA版-P458）"><a href="#Executor框架两级调度（Java岗面试核心MCA版-P458）" class="headerlink" title="Executor框架两级调度（Java岗面试核心MCA版 P458）"></a>Executor框架两级调度（Java岗面试核心MCA版 P458）</h3><p>在上层，JAVA程序会将应用分解为多个任务，然后使用应用级的调度器(Executor)将这些任务映射成固定数量的线程;在底层，操作系统内核将这些线程映射到硬件处理器上</p>
<p>Runnable和Callable是工作单元(也就是俗称的任务)，执行机制由Executor来提 供。Executor是基于<strong>生产者消费者模式</strong></p>
<h3 id="线程池与线程组"><a href="#线程池与线程组" class="headerlink" title="线程池与线程组"></a>线程池与线程组</h3><p><strong>线程组</strong>就表示一个线程的集合</p>
<p><strong>线程池</strong>是为<strong>线程的生命周期开销问题和资源不足问题</strong>提供解决方案，主要用来管理线程；如果每当一个请求到达就创建一个新线程，开销是相当大的</p>
<p><strong>Callable是Runnable封装的异步运算任务<br>Future用来保存Callable异步运算的结果<br>FutureTask封装Future的实体类</strong></p>
<h3 id="Callable与Runnbale的区别"><a href="#Callable与Runnbale的区别" class="headerlink" title="Callable与Runnbale的区别"></a>Callable与Runnbale的区别</h3><p>a、Callable定义的方法是call，而Runnable定义的方法是run<br>b、call方法有返回值，而run方法是没有返回值的<br>c、call方法可以抛出异常，而run方法不能抛出异常</p>
<pre><code>public class MyCallableTask implements Callable&lt;Integer&gt; &#123;
@Override
public Integer call()
&#123;
        System.out.println(&quot;callable do somothing&quot;);
        Thread.sleep(5000);
        return new Random().nextInt(100);
    &#125;
&#125;

Callable&lt;Integer&gt; callable = new MyCallableTask();
FutureTask&lt;Integer&gt; future = new FutureTask&lt;Integer&gt;(callable);
Thread thread = new Thread(future);
thread.start();
Thread.sleep(100);
future.cancel(true);
</code></pre>
<h3 id="什么是线程安全，如何实现线程安全"><a href="#什么是线程安全，如何实现线程安全" class="headerlink" title="什么是线程安全，如何实现线程安全"></a>什么是线程安全，如何实现线程安全</h3><p>线程安全：线程执行过程中不会产生共享资源的冲突<br>线程不安全：如果有多个线程同时在操作主内存中的变量</p>
<h3 id="Java多线程安全机制"><a href="#Java多线程安全机制" class="headerlink" title="Java多线程安全机制"></a>Java多线程安全机制</h3><h4 id="互斥同步（阻塞同步，悲观）"><a href="#互斥同步（阻塞同步，悲观）" class="headerlink" title="互斥同步（阻塞同步，悲观）"></a>互斥同步（阻塞同步，悲观）</h4><p>最基本的就是<strong>synchronized关键字</strong>，执行时，会有monitorenter指令和monitorexit指令，monitorenter指令尝试获取对象的锁，或者给锁的计数器加1；monitorexit指令会给锁的计数器减1，获取失败就阻塞等待</p>
<p>还有java.util.concurrent包中的<strong>ReentrantLock重入锁</strong>，基本用法相似，目前性能接近</p>
<h4 id="非阻塞同步（乐观）"><a href="#非阻塞同步（乐观）" class="headerlink" title="非阻塞同步（乐观）"></a>非阻塞同步（乐观）</h4><p><strong>操作和冲突检测，具备原子性</strong><br><strong>Test-and-Set, Fetch-and-Increment, Swap, Compare-and-Swap(CAS)</strong></p>
<h4 id="无同步方案"><a href="#无同步方案" class="headerlink" title="无同步方案"></a>无同步方案</h4><h4 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h4><h4 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h4><p>一个变量被定义为volatile后，保证此变量对<strong>所有线程可见性</strong>，普通变量做不到，因为普通变量在线程间传递需要通过主内存</p>
<p><strong>volatile变量在使用之前需要先从主内存刷新最新的值</strong>，执行引擎看不到不一致的情况，但是Java内的运算操作符不是原子操作，所以若不满足以下两条规则，仍要通过加锁保证原子性：</p>
<p>1.运算结果不依赖变量当前值，或只有单一线程修改变量值</p>
<p>2.变量不需要与其他状态变量共同参与不变约束</p>
<p>Java虚拟机书P446有例子，<strong>volatile关键字很适合控制并发（状态标志），例如：其他线程看到某一标志变量变化了，就停止线程</strong></p>
<h4 id="禁止指令重排序优化"><a href="#禁止指令重排序优化" class="headerlink" title="禁止指令重排序优化"></a>禁止指令重排序优化</h4><p>volatile修饰的变量会建立<strong>内存屏障</strong>，指重排序不能把后面的指令重排序到内存屏障之前的位置，例如：<strong>lock</strong> addl xxxxx</p>
<p>其中，<strong>lock前缀将本处理器的缓存写入内存，同时其他处理器缓存无效化</strong>，就建立了内存屏障</p>
<p><strong>synchronized关键字，一个变量在同一个时刻只允许一条线程进行lock操作</strong></p>
<h3 id="synchronized、volatile区别"><a href="#synchronized、volatile区别" class="headerlink" title="synchronized、volatile区别"></a>synchronized、volatile区别</h3><p>volatile仅能使用在<strong>变量级别</strong>，仅能实现变量的修改可见性，<strong>不能保证原子性</strong>，<strong>不会被编译器优化</strong></p>
<p>synchronized则可以使用在<strong>变量、方法、和类级别</strong>的，可以保证变量的修改可见性和原子性，因为线程获得锁才能进入临界区，<strong>可以被编译器优化</strong></p>
<h3 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h3><p>处理器与内存之间——高速缓存</p>
<p>多个处理器，多个缓存，共享内存，带来的<strong>缓存一致性问题</strong></p>
<p>通过缓存一致性协议协调</p>
<p><strong>happens-before规则</strong></p>
<h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><p><strong>ThreadLocal是一个本地线程副本变量工具类，主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰</strong></p>
<p>每个Thread线程内部都有一个ThreadLocalMap。<br>Map里面存储线程本地对象ThreadLocal（key）和线程的变量副本（value）</p>
<p>Thread内部的Map是由ThreadLocal维护，ThreadLocal负责向map获取和设置线程的变量值。<br>一个Thread可以有多个ThreadLocal</p>
<h3 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h3><p>1.8的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构<br>利用了CAS对数组的某个位置进行并发安全的赋值</p>
<h3 id="CAS（Compare-and-Swap）"><a href="#CAS（Compare-and-Swap）" class="headerlink" title="CAS（Compare-and-Swap）"></a>CAS（Compare-and-Swap）</h3><p>CAS指令需要三个操作数，分别是内存地址（在Java内存模型中可以简单理解为主内存中变量的内存地址）、旧值（在Java内存模型中，可以理解工作内存中缓存的主内存的变量的值）和新值。<strong>CAS操作执行时，当且仅当主内存对应的值等于旧值时，处理器用新值去更新旧值，否则它就不执行更新</strong>。但是无论是否更新了主内存中的值，都会返回旧值，上述的处理过程是一个原子操作。<br>如果线程中的值和主内存中的值不一致，根据缓存一致性原则，会重新去主内存读取a的值（11）</p>
<p><strong>CAS 操作是抱着乐观的态度进行的(乐观锁)，它总是认为自己可以成功完成操作。当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。</strong></p>
<h3 id="CountDownLatch、CyclicBarrier、Semaphore的用法和区别"><a href="#CountDownLatch、CyclicBarrier、Semaphore的用法和区别" class="headerlink" title="CountDownLatch、CyclicBarrier、Semaphore的用法和区别"></a>CountDownLatch、CyclicBarrier、Semaphore的用法和区别</h3><p>CountDownLatch 类位于 java.util.concurrent 包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了</p>
<p>回环屏障，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用</p>
<p>Semaphore翻译成字面意思为 信号量，Semaphore 可以同时让多个线程同时访问共享资源，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java学习笔记——11.24</title>
    <url>/2023/11/24/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%9411-24/</url>
    <content><![CDATA[<h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><h4 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h4><p>保证一个类只能有一个实例，并提供一个全局访问点</p>
<p>单例类的构造函数必须是私有的，这样才能将类的创建权控制在类的内部，从而使得类的外部不能创建类的实例；单例类通过一个私有的静态变量来存储其唯一实例；单例类通过提供一个公开的静态方法，使得外部使用者可以访问类的唯一实例</p>
<p>1.饿汉式</p>
<pre><code>public class Singleton &#123; 
    private static final Singleton instance = new Singleton();
    
    private Singleton () &#123;&#125;
    
    public static Singleton getInstance() &#123;
        return instance;
    &#125;
&#125;
</code></pre>
<p>优点：线程安全，获取单例对象不需加锁<br>缺点：不是延时加载</p>
<p>2.懒汉式</p>
<p>懒汉式为了支持延时加载，将对象的创建延迟到了获取对象的时候，但为了线程安全，不得不为获取对象的操作加锁；并且这把锁只有在第一次创建对象时有用，而之后每次获取对象，这把锁都是一个累赘</p>
<pre><code>public class Singleton &#123; 
    private static final Singleton instance;
    
    private Singleton () &#123;&#125;
    
    public static synchronized Singleton getInstance() &#123;    
        if (instance == null) &#123;      
        instance = new Singleton();    
        &#125;    

        return instance;  
    &#125;
&#125;
</code></pre>
<p>3.双重检测，懒汉式plus<br>    public class Singleton {<br>        private static Singleton instance;</p>
<pre><code>    private Singleton () &#123;&#125;
    
    public static Singleton getInstance() &#123;
        if (instance == null) &#123;
        synchronized(Singleton.class) &#123; // 注意这里是类级别的锁
            if (instance == null) &#123;       // 这里的检测避免多线程并发时多次创建对象
            instance = new Singleton();
            &#125;
        &#125;
        &#125;
        return instance;
    &#125;
&#125;
</code></pre>
<p>将锁方法变成锁代码块</p>
<p>第二次校验是关键，这里防止了多线程创建多个实例（一般为两个），这里的特殊情况是这样的：在未创建实例的情况下，A线程和B线程都通过了第一次校验（singletonDoubleCheck为空）,<strong>这时如果通过竞争B线程拿到了锁就会执行一次new操作，生成一个实例，然后B执行完了A就会拿到资源的锁，如果没有第二次判断的话，这时A线程也会执行一次new操作，这里就出现了第二个类实例，违背了单例原则</strong>。所以说两次校验都是必不可少的。</p>
<p>作者：chenq877<br>链接：<a href="https://juejin.cn/post/7049327348784562213">https://juejin.cn/post/7049327348784562213</a><br>来源：稀土掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>参考链接<br><a href="https://www.cnblogs.com/codeshell/p/14177102.html">https://www.cnblogs.com/codeshell/p/14177102.html</a></p>
<h4 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h4><p>工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>工厂模式提供了一种将对象的实例化过程封装在工厂类中的方式。通过使用工厂模式，可以将对象的创建与使用代码分离，提供一种统一的接口来创建不同类型的对象。</p>
<h3 id="Java-GC机制"><a href="#Java-GC机制" class="headerlink" title="Java GC机制"></a>Java GC机制</h3><h4 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h4><p>对象中引用计数器，为0时回收</p>
<p>问题：当有对象相互引用时，无法回收</p>
<h4 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h4><p>GC Root Set<br>通过一系列称为<strong>GC Roots</strong>的根对象作为起始节点集，搜索引用链</p>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><p><strong>强引用</strong> 赋值引用</p>
<p><strong>软引用</strong> 有用，非必须，OOM前会回收</p>
<p><strong>弱引用</strong> 有用，非必须。下一次垃圾收集前回收</p>
<p><strong>虚引用</strong> 即将被回收，通知系统回收</p>
<h3 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h3><h4 id="分代收集理论"><a href="#分代收集理论" class="headerlink" title="分代收集理论"></a>分代收集理论</h4><p>两个分代假说：<br><strong>1.弱分代假说</strong>：绝大多数对象都是朝生夕死的</p>
<p><strong>2.强分代假说</strong>：熬过越多次垃圾收集过程的对象越难消亡</p>
<p><strong>3.跨代引用假说</strong>：跨代引用相对于同代引用来说，只占极少数<br>只需在新生代建立一个全局数据结构，把老年代划分为若干小块，表示哪一块存在跨代引用</p>
<h4 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h4><p>1.对需要回收的对象打标记<br>2.对存活的对象打标记</p>
<p><strong>问题：</strong><br>1.<strong>对象较多时，标记开销会很大</strong><br>2.只标记清除，不整理，会存在<strong>内存碎片化</strong>问题；内存分配可能效率低</p>
<h4 id="标记-复制算法"><a href="#标记-复制算法" class="headerlink" title="标记-复制算法"></a>标记-复制算法</h4><p>分1：1的两个半区，当当前半区内存用完时，每次将存活的对象复制到另外的半区</p>
<p>问题：每次有一半内存没用上，浪费了</p>
<p>假设：新生代中98%的对象活不过第一轮收集<br><strong>优化：Eden空间 + 2个Survivor空间（Eden和Survivor空间比，8:1）</strong><br>若Survivor装不下，直接进入老年代</p>
<h4 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h4><p>每次让存活的对象都向内存空间另一端移动，然后直接清理边界以外的内存</p>
<p><strong>和清除对比：移动的话，内存回收代价大；清除的话，内存分配代价大</strong><br>也可以两者结合，自然的，先清除，碎片化程度太大时进行移动即可</p>
<h4 id="可达性分析"><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h4><p>白色：没访问到<br>灰色：这个对象上至少还有一个引用没扫描过<br>黑色：这个对象被访问，且所有引用都已经被扫描过</p>
<p>对象消失问题：书P89例子<br>增量更新：黑色对象插入新的指向白色的引用，记录下来，最后重新扫描<br>原始快照（SATB）：灰色对象要删除指向白色的对象引用时，记录下来，最后重新扫描</p>
<h3 id="经典垃圾收集器"><a href="#经典垃圾收集器" class="headerlink" title="经典垃圾收集器"></a>经典垃圾收集器</h3><h4 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h4><p>新生代，<strong>单线程</strong>，需要暂停其他所有工作线程<br>新生代采用复制算法，老年代采用标记-整理算法</p>
<h4 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h4><p>老年代，标记-整理算法</p>
<h4 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h4><p>Serial收集器的多线程版本，对于新生代的收集，采用<strong>多GC线程</strong>复制算法</p>
<h4 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h4><p>新生代，标记-复制算法，<strong>期望达到一个可控制的吞吐量</strong></p>
<p>参数：MaxGCPauseMills最大GC停顿时间；GCTimeRatio直接设置吞吐量大小</p>
<h4 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h4><p>Parallel Scavenge的老年代版本，多线程收集，标记-整理算法</p>
<h4 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h4><p>四个步骤：（标记-清除算法）</p>
<p><strong>初始标记</strong> 标记GC Roots直接关联到的对象，需要停顿</p>
<p><strong>并发标记</strong> 可达性分析，遍历整个对象图，但和用户进程并发进行，不需要停顿</p>
<p><strong>重新标记</strong> 修正并发标记期间，标记产生变动的那一部分对象的标记记录，需要停顿</p>
<p><strong>并发清除</strong> 清除标记阶段判断的已经死亡的对象，不需要停顿</p>
<p>缺点：<br>1.无法处理浮动垃圾，我理解就是并发标记期间，得给那些新对象预留空间，避免堆满触发FullGC<br>2.因为是标记-清除算法，存在内存碎片问题</p>
<h4 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h4><p>基于Region的堆内存布局，划分为多个相同大小的独立Region，可以扮演Eden，Suvivor，老年代空间的不同角色</p>
<p>还有特殊的Humongous区域用来专门存储大对象（超过一个Region空间一半）</p>
<p><strong>回收思路：</strong>跟踪各个Region中垃圾堆积的<strong>价值大小</strong>，即回收所获得的空间和回收所需时间的经验值，再维护一个<strong>优先级列表</strong></p>
<p>四个步骤</p>
<p>初始标记 标记GC Roots直接关联到的对象，需要停顿</p>
<p>并发标记 可达性分析</p>
<p>最终标记 处理遗留下来的少量SATB记录</p>
<p>筛选回收 更新Region统计数据，根据价值和成本排序，回收</p>
<p>缺点：内存占用和程序运行的额外执行负载更高</p>
<h4 id="ZGC收集器"><a href="#ZGC收集器" class="headerlink" title="ZGC收集器"></a>ZGC收集器</h4><p>Region分为小型Region、中型Region、大型Region</p>
<p>染色指针</p>
<h3 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h3><h4 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h4><p>1.加载，通过一个类的全限定名获取二进制字节流，将字节流所代表的静态存储结构转化为方法区的运行时数据结构，生成一个java.lang.Class对象</p>
<p>2.验证，验证这个class文件，包括文件格式校验、元数 据验证，字节码校验</p>
<p>3.准备，对这个对象分配内存，仅类变量，且通常情况赋值0，而不是代码中的值；仅在final修饰的常量值赋值代码中的值</p>
<p>4.解析，将符号引用转化为直接引用</p>
<p>5.初始化，执行构造器代码</p>
<h4 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h4><p>判断两个类是否相等：<strong>来源于同一个Class文件+同一个Java类加载器加载</strong></p>
<p><strong>从Java虚拟机角度看</strong>，只有两种类加载器：<br>1.启动类加载器，是虚拟机自身的一部分</p>
<p>2.其他所有类的加载器，独立于虚拟机之外，继承自java.lang.ClassLoader</p>
<p><strong>从Java开发人员角度看</strong>，有三种类加载器：<br>1.启动类加载器，用来加载 java 核心类库，无法被 java 程序直接引用</p>
<p>2.扩展类加载器，用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个<br>扩展库目录。该类加载器在此目录里面查找并加载 Java 类</p>
<p>3.应用程序类加载器，通过继承 java.lang.ClassLoader 类的方式实现</p>
<h4 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h4><p>工作过程：如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达<strong>顶层的启动类加载器</strong>，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载</p>
<h4 id="破坏双亲委派模型"><a href="#破坏双亲委派模型" class="headerlink" title="破坏双亲委派模型"></a>破坏双亲委派模型</h4><h3 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h3><p><a href="https://www.bilibili.com/video/BV1Hs411j73w/?share_source=copy_web&amp;vd_source=b9fdf8380afcac3eebf150a26e73ff50">https://www.bilibili.com/video/BV1Hs411j73w/?share_source=copy_web&amp;vd_source=b9fdf8380afcac3eebf150a26e73ff50</a></p>
<p>普通哈希算法在服务器数量变化时的缓存失效，雪崩问题</p>
<p>一致性哈希只影响部分资源，其余部分资源不受影响</p>
<h4 id="缓存偏斜问题"><a href="#缓存偏斜问题" class="headerlink" title="缓存偏斜问题"></a>缓存偏斜问题</h4><p>引入虚拟节点，平衡访问</p>
<h4 id="减少哈希冲突"><a href="#减少哈希冲突" class="headerlink" title="减少哈希冲突"></a>减少哈希冲突</h4><p>Redis——<a href="https://cloud.tencent.com/developer/article/2313606">https://cloud.tencent.com/developer/article/2313606</a><br>rehash：Redis的rehash是指在哈希表扩容或缩小时，重新计算并重新分配所有键值对的过程。rehash的目的是为了保持哈希表的负载因子在一个合理的范围内，以提高哈希表的性能。</p>
<p>在Redis中，rehash是一个渐进式的过程，它不会一次性地将所有键值对重新分配到新的哈希表中，而是分多次进行，每次处理一小部分键值对。这种渐进式的rehash过程可以保证在rehash期间，Redis仍然可以正常处理读取和写入操作，不会阻塞客户端请求</p>
<h4 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h4><p>具体的rehash过程如下：</p>
<p><strong>1.Redis会创建一个新的空哈希表，大小是当前哈希表的两倍（或更小，如果是缩小操作）。</strong><br>2.Redis会将当前哈希表的rehashidx属性设置为0，表示rehash的起始位置。<br>3.<strong>在每次执行读取或写入操作时，Redis会同时对当前哈希表和新哈希表进行操作。</strong><br><strong>4.对于读取操作，Redis首先在当前哈希表中查找键值对，如果找不到，则继续在新哈希表中查找。</strong><br><strong>5.对于写入操作，Redis会将新的键值对添加到新哈希表中，同时保留当前哈希表中的键值对。</strong><br><strong>6.在每次执行完一定数量的操作后，Redis会逐步将当前哈希表中的键值对迁移到新哈希表中，直到迁移完成。</strong></p>
<h4 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h4><p><strong>字符串String</strong></p>
<p><strong>列表List</strong><br><strong>压缩列表（Ziplist）和双向链表（Doubly Linked List）</strong><br>列表长度和列表元素大小超过一定阈值，改为双向链表</p>
<p><strong>集合Set</strong><br><strong>哈希表（Hash Table）和跳跃表（Skip List）</strong></p>
<p>哈希表适用于存储大量元素的集合，并且对于查找操作的性能要求较高</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>快手——Java电商——一面凉经</title>
    <url>/2023/11/28/%E5%BF%AB%E6%89%8B%E2%80%94%E2%80%94Java%E7%94%B5%E5%95%86%E2%80%94%E2%80%94%E4%B8%80%E9%9D%A2%E5%87%89%E7%BB%8F/</url>
    <content><![CDATA[<h4 id="面试过程"><a href="#面试过程" class="headerlink" title="面试过程"></a>面试过程</h4><p>10min项目+30min拷打<br>面试官还是很耐心的，很多问题我答的可以说很烂，最后还是愿意跟我聊问题，怎么提升</p>
<h4 id="项目亮点，收获"><a href="#项目亮点，收获" class="headerlink" title="项目亮点，收获"></a>项目亮点，收获</h4><p>表述清楚，用程序员语言描述</p>
<p><strong>不match</strong></p>
<h4 id="SQL题，统计一个小学7～12岁的年龄分布-id-name-age"><a href="#SQL题，统计一个小学7～12岁的年龄分布-id-name-age" class="headerlink" title="SQL题，统计一个小学7～12岁的年龄分布 id name age"></a>SQL题，统计一个小学7～12岁的年龄分布 id name age</h4><p>select count(id) from xxx where 7&lt;&#x3D;age ans age&lt;&#x3D;12 order by age</p>
<p>不要用等于号</p>
<h4 id="分析题"><a href="#分析题" class="headerlink" title="分析题"></a>分析题</h4><p>Integer b &#x3D; null;<br>int a &#x3D; 0;<br>a &#x3D;&#x3D; b;<br>实际上会报异常，因为Integer是一个对象，对于b来说，b&#x3D;&#x3D;null还没分配内存，还没有这个对象，根本不涉及拆箱装箱</p>
<h4 id="Object-a-x3D-new-Object-实际发生了什么"><a href="#Object-a-x3D-new-Object-实际发生了什么" class="headerlink" title="Object[] a &#x3D; new Object[]实际发生了什么"></a>Object[] a &#x3D; new Object[]实际发生了什么</h4><p><a href="https://juejin.cn/post/7265679390242947112">https://juejin.cn/post/7265679390242947112</a></p>
<h4 id="面向对象三大特性？封装、继承、多态"><a href="#面向对象三大特性？封装、继承、多态" class="headerlink" title="面向对象三大特性？封装、继承、多态"></a>面向对象三大特性？封装、继承、多态</h4><p>解释一下多态<br><a href="https://www.cnblogs.com/chenssy/p/3372798.html">https://www.cnblogs.com/chenssy/p/3372798.html</a><br><a href="https://blog.csdn.net/thinkGhoster/article/details/2307001">https://blog.csdn.net/thinkGhoster/article/details/2307001</a><br>多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性</p>
<p>我们只有在运行的时候才会知道引用变量所指向的具体实例对象。</p>
<p>Wine a &#x3D; new JNC();</p>
<p>在这里我们这样理解，这里定义了一个Wine 类型的a，它指向JNC对象实例。由于JNC是继承与Wine，所以JNC可以自动<strong>向上转型为Wine</strong>，所以a是可以指向JNC实例对象的。这样做存在一个非常大的好处，在继承中我们知道子类是父类的扩展，它可以提供比父类更加强大的功能，如果我们定义了一个指向子类的父类引用类型，那么它除了能够引用父类的共性外，还可以使用子类强大的功能。</p>
<p>父类类型的引用可以调用父类中定义的所有属性和方法，对于只存在与子类中的方法和属性它就望尘莫及了</p>
<p><strong>指向子类的父类引用由于向上转型了，它只能访问父类中拥有的方法和属性，而对于子类中存在而父类中不存在的方法，该引用是不能使用的，尽管是重载该方法。若子类重写了父类中的某些方法，在调用该些方法的时候，必定是使用子类中定义的这些方法（动态连接、动态调用）</strong></p>
<h4 id="方法表角度思考多态（自）"><a href="#方法表角度思考多态（自）" class="headerlink" title="方法表角度思考多态（自）"></a>方法表角度思考多态（自）</h4><p><strong>jvm会为每一个类预先计算一个方法表，列出所有方法的签名和要调用的实际方法</strong><br>在动态方法调度中，对象可以调用子类的覆盖方法和基类的所有非覆盖方法，但是<strong>它不能调用子类中新声明的方法</strong>，我理解重载的话，和父类中的函数签名不同，也算是个新方法了，不能在动态方法中调用</p>
<p>父类的方法表肯定就只有父类的方法，子类的方法表会有所有<strong>父类中未被覆盖的方法</strong>和<strong>子类覆盖的方法</strong>和<strong>新方法和重载的方法</strong>，</p>
<h4 id="多态是在运行时还是在编译时，多态是如何实现的"><a href="#多态是在运行时还是在编译时，多态是如何实现的" class="headerlink" title="多态是在运行时还是在编译时，多态是如何实现的"></a>多态是在运行时还是在编译时，多态是如何实现的</h4><p><strong>多态分为编译时多态和运行时多态。其中编译时多态是静态的，主要是指方法的重载，它是根据参数列表的不同来区分不同的函数，通过编译之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们所说的多态性。</strong></p>
<p><strong>动态绑定：</strong>在<strong>运行时</strong>根据具体对象的类型进行绑定</p>
<p><strong>静态绑定：</strong>在程序执行前方法已经被绑定  <strong>编译过程确定</strong></p>
<h4 id="多态机制原则"><a href="#多态机制原则" class="headerlink" title="多态机制原则"></a>多态机制原则</h4><p><strong>当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法</strong>，但是它仍然要根据继承链中方法调用的优先级来确认方法，该优先级为：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)。</p>
<h4 id="equals-和-x3D-x3D-区别"><a href="#equals-和-x3D-x3D-区别" class="headerlink" title="equals()和&#x3D;&#x3D;区别"></a>equals()和&#x3D;&#x3D;区别</h4><p>Person a  Person b怎么equals</p>
<p>需要重写equals方法，一般认为各个字段相同，就是对象相同</p>
<h4 id="wait-和sleep-区别，哪个释放CPU资源"><a href="#wait-和sleep-区别，哪个释放CPU资源" class="headerlink" title="wait()和sleep()区别，哪个释放CPU资源"></a>wait()和sleep()区别，哪个释放CPU资源</h4><p>都释放，但sleep不释放锁资源，wait释放锁资源<br><a href="https://juejin.cn/post/7062988072039743525">https://juejin.cn/post/7062988072039743525</a></p>
<h4 id="异常都有什么"><a href="#异常都有什么" class="headerlink" title="异常都有什么"></a>异常都有什么</h4><p><a href="https://pdai.tech/md/java/basic/java-basic-x-exception.html">https://pdai.tech/md/java/basic/java-basic-x-exception.html</a><br>答：IndexOutOfBoundsException 越界异常，被问了下异常全名<br>NullPointerException 空指针异常<br>OutOfMemoryException</p>
<p><strong>运行时异常</strong><br>都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生</p>
<p><strong>非运行时异常（编译异常）</strong><br>是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。</p>
<h4 id="OutOfMemory异常——OOM"><a href="#OutOfMemory异常——OOM" class="headerlink" title="OutOfMemory异常——OOM"></a>OutOfMemory异常——OOM</h4><p><a href="https://blog.51cto.com/u_14499/7147575">https://blog.51cto.com/u_14499/7147575</a><br>1.<strong>Java堆溢出</strong>，不断的创建对象，总容量触及最大堆的容量限制；要判断是内存泄漏还是内存溢出，如果是内存泄漏，通过Dump出来的堆转储快照进行分析，找泄漏变量的引用路径和哪些GCRoots相关联；如果是内存溢出，对象都必须活着，要么调整堆参数，要么检查是否有对象生命周期过长，存储结构设计不合理等</p>
<p>2.<strong>虚拟机栈和本地方法栈溢出</strong><br>如果线程请求的栈深度大于jvm允许的深度，StackOverflowError异常<br>如果jvm容量可以动态扩展，当扩展到无法申请到足够内存时，抛出OutOfMemoryError异常</p>
<p>3.<strong>方法区和运行时常量池溢出</strong><br>运行时常量池包括字段引用以及常量，当常量池没有足够内存可用时<br>方法区在无法满足新内存分配需求时，会OOM</p>
<p>4.<strong>本机直接内存溢出</strong><br>程序直接或间接的使用了直接内存</p>
<h4 id="什么对象不会被回收"><a href="#什么对象不会被回收" class="headerlink" title="什么对象不会被回收"></a>什么对象不会被回收</h4><p>引用计数法</p>
<p>可达性分析法</p>
<h4 id="Java线程安全"><a href="#Java线程安全" class="headerlink" title="Java线程安全"></a>Java线程安全</h4><h4 id="synchronized关键字"><a href="#synchronized关键字" class="headerlink" title="synchronized关键字"></a>synchronized关键字</h4><p><a href="https://pdai.tech/md/java/thread/java-thread-x-key-synchronized.html">https://pdai.tech/md/java/thread/java-thread-x-key-synchronized.html</a><br><strong>锁粒度问题</strong><br>1.synchronized用来标识一个<strong>普通方法</strong>，表示一个线程要执行该方法，必须取得该方法所在的<strong>对象的锁</strong></p>
<p>2.synchronized用来标识一个<strong>静态方法</strong>，表示一个线程要执行该方法，必须取得该方法所在的<strong>类的类锁</strong></p>
<p>3.synchronized用来修饰一个代码块，表示一个线程要执行该代码块，必须获得obj的锁</p>
<h4 id="Java-web流程"><a href="#Java-web流程" class="headerlink" title="Java web流程"></a>Java web流程</h4><p>比如一个手机想客户端发请求，到返回请求，处理流程</p>
]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
</search>
